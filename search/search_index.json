{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Fenswood Farm \u00b6 Introduction \u00b6 This repository provides a tutorial, template and overview for running the Fenswood Scenario in detail. It will take the student through the basics of Linux, Ros and Docker to hopefully run and edit the Fenswood Scenario simulation environment, followed by developing a simple controller to hopefully fly a drone! This tutorial is split into two parts. Basics of Linux, ROS and Docker on this site (starting here): https://starlinguas.github.io/FenswoodScenario/tutorials/fenswood_scenario/ Fenswood Volcano Template Tutorials where you will learn how to create and build your controller https://starlinguas.github.io/fenswood_volcano_template/ How to use this Tutorial \u00b6 This Tutorial aims to give an introductory overview of the Starling system through the use of the Fenswood Scenario example. It will take a student from the basics of Linux, ROS and Docker to hopefully being able to run the Fenswood Scenario simulation environment with a simple controller flying the drone. Simply follow along and try and consider what each command is doing. This tutorial was written for the University of Bristol Aerial MSc Group Project 2021.","title":"Fenswood Farm"},{"location":"#fenswood-farm","text":"","title":"Fenswood Farm"},{"location":"#introduction","text":"This repository provides a tutorial, template and overview for running the Fenswood Scenario in detail. It will take the student through the basics of Linux, Ros and Docker to hopefully run and edit the Fenswood Scenario simulation environment, followed by developing a simple controller to hopefully fly a drone! This tutorial is split into two parts. Basics of Linux, ROS and Docker on this site (starting here): https://starlinguas.github.io/FenswoodScenario/tutorials/fenswood_scenario/ Fenswood Volcano Template Tutorials where you will learn how to create and build your controller https://starlinguas.github.io/fenswood_volcano_template/","title":"Introduction"},{"location":"#how-to-use-this-tutorial","text":"This Tutorial aims to give an introductory overview of the Starling system through the use of the Fenswood Scenario example. It will take a student from the basics of Linux, ROS and Docker to hopefully being able to run the Fenswood Scenario simulation environment with a simple controller flying the drone. Simply follow along and try and consider what each command is doing. This tutorial was written for the University of Bristol Aerial MSc Group Project 2021.","title":"How to use this Tutorial"},{"location":"details/attach_detach/","text":"Payload pick up and drop off \u00b6 Added for the project 2022-2023 A new scenario has been created where the user needs to drop off a sensor package at the caldera of the vehicle, and then after sampling for a minute, pick it back up again. This repository contains a simplified version of these mechanics which model its usage through ros topics, but not the physics of actually picking up and depositing an object, as well as ignoring the effect of a payload on the dynamics of the flight. Therefore the mechanics can be summarised as follows. The vehicle spawns above a sensor payload and initially attempts to attach to it when the vehicle is within 1m above the payload. The payload is rigidly attached. The vehicle should fly as normal with the payload to the caldera On deposit, the user sends a {\"data: false\"} topic to /attach_vehicle/control in order to detach the payload. On pick up, the vehicle flies within 1m above the payload and sends a {\"data: true\"} topic to /attach_vehicle/control in order to attach the payload. Note that this mechanic is only available if using the fenswood_with_payload.world . This world file also contains some of the parameters for this rosnode. Attaching Ros Node \u00b6 The ros/gazebo node which governs the connection is in simulation/attach_vehicles_plugin . It is a bit of reused code from a UGV/UAV project which allowed one to carry the other. In short, in gazebo, it is exceedingly difficult to model proper collision. Any attempt to use the physics engine to \"pick up\" and object will end up with extreme numerical errors and effects such as rubber banding and the like. Therefore we use a shortcut where we physically join the two models together rigidly in a dynamic fashion. This plugin essentially monitors a drone_model and a payload_model . It creates one Publisher and one Subscriber of the following attach_vehicle/control (std_msgs/Bool): Subscriber to attempt to attach (true) or detach (false) the payload attach_vehicle/status (std_msgs/Bool): Publisher to show the status of the attaching. True for attached, False for detached. When an attach command is requested, it goes into the simulation and finds the drone and payload models. A model in gazebo is made up of static links (contains geometry, collision, etc) and joints which join the links together. It gets the root link (a.k.a the base_link) of each of these models and checks the distances to each other. Currently it checks that the drone is within allowable_offset_height height above the payload, and within allowable_offset_horizontal in the X,Y plane. If the models are within the tolerated distance, a joint is dynamically created which rigidly joins the vehicle to the payload. When a detach command is requested, this dynamic joint is removed. NOTE At simulation startup, the vehicle and payload use the same attach mechanic to initially attach to each other. Sometimes this can fail (e.g. if the payload falls through the world for some reason). The distance between the vehicle and the payload is logged. If this fails, restart the simulation. If it continually happens, your computer may be struggling with the load. Implementing support in your controllers \u00b6 As mentioned above, this mechanic only uses simply rostopics. Therefore in your controller you will only need to add a new Publisher/Subscriber pair. Then when you want the attach/detach to happen, you will need to publish a std_msgs/msg/Bool to the Publisher. The standard ROS2 docs should cover this use case in both Python and CPP.","title":"Pick up & Drop off of Payload"},{"location":"details/attach_detach/#payload-pick-up-and-drop-off","text":"Added for the project 2022-2023 A new scenario has been created where the user needs to drop off a sensor package at the caldera of the vehicle, and then after sampling for a minute, pick it back up again. This repository contains a simplified version of these mechanics which model its usage through ros topics, but not the physics of actually picking up and depositing an object, as well as ignoring the effect of a payload on the dynamics of the flight. Therefore the mechanics can be summarised as follows. The vehicle spawns above a sensor payload and initially attempts to attach to it when the vehicle is within 1m above the payload. The payload is rigidly attached. The vehicle should fly as normal with the payload to the caldera On deposit, the user sends a {\"data: false\"} topic to /attach_vehicle/control in order to detach the payload. On pick up, the vehicle flies within 1m above the payload and sends a {\"data: true\"} topic to /attach_vehicle/control in order to attach the payload. Note that this mechanic is only available if using the fenswood_with_payload.world . This world file also contains some of the parameters for this rosnode.","title":"Payload pick up and drop off"},{"location":"details/attach_detach/#attaching-ros-node","text":"The ros/gazebo node which governs the connection is in simulation/attach_vehicles_plugin . It is a bit of reused code from a UGV/UAV project which allowed one to carry the other. In short, in gazebo, it is exceedingly difficult to model proper collision. Any attempt to use the physics engine to \"pick up\" and object will end up with extreme numerical errors and effects such as rubber banding and the like. Therefore we use a shortcut where we physically join the two models together rigidly in a dynamic fashion. This plugin essentially monitors a drone_model and a payload_model . It creates one Publisher and one Subscriber of the following attach_vehicle/control (std_msgs/Bool): Subscriber to attempt to attach (true) or detach (false) the payload attach_vehicle/status (std_msgs/Bool): Publisher to show the status of the attaching. True for attached, False for detached. When an attach command is requested, it goes into the simulation and finds the drone and payload models. A model in gazebo is made up of static links (contains geometry, collision, etc) and joints which join the links together. It gets the root link (a.k.a the base_link) of each of these models and checks the distances to each other. Currently it checks that the drone is within allowable_offset_height height above the payload, and within allowable_offset_horizontal in the X,Y plane. If the models are within the tolerated distance, a joint is dynamically created which rigidly joins the vehicle to the payload. When a detach command is requested, this dynamic joint is removed. NOTE At simulation startup, the vehicle and payload use the same attach mechanic to initially attach to each other. Sometimes this can fail (e.g. if the payload falls through the world for some reason). The distance between the vehicle and the payload is logged. If this fails, restart the simulation. If it continually happens, your computer may be struggling with the load.","title":"Attaching Ros Node"},{"location":"details/attach_detach/#implementing-support-in-your-controllers","text":"As mentioned above, this mechanic only uses simply rostopics. Therefore in your controller you will only need to add a new Publisher/Subscriber pair. Then when you want the attach/detach to happen, you will need to publish a std_msgs/msg/Bool to the Publisher. The standard ROS2 docs should cover this use case in both Python and CPP.","title":"Implementing support in your controllers"},{"location":"details/building_from_source/","text":"Building Fenswood Scenario and the Simulator Stack from Source \u00b6 This tutorial takes the reader through how to build the simulator stack and the necessary requirements for the Fenswood Project scenario from source. THIS IS RECOMMENDED FOR THOSE RUNNING ON ARM64 ARCHITECTURES This includes the new Mac models running M1 chipsets. Building Fenswood Scenario and the Simulator Stack from Source The System Building The System Building the core functionality Building the Fenswood Scenario The System \u00b6 This repository builds upon the ProjectStarling set of containers and therefore requires the following containers to be built Ardupilot core gazebo simulator ( uobflightlabstarling/starling-sim-iris-ap ) Ardupilot SITL ( uobflightlabstarling/starling-sim-ardupilot-copter ) Mavros ( uobflightlabstarling/starling-mavros ) Rosbridge Suite ( uobflightlabstarling/rosbridge-suite ) Controller Base ( uobflightlabstarling/starling-controller-base ) FenswoodScenario simulator ( uobflightlabstarling/starling-sim-iris-ap ) which is built upon (1) Warning These containers are all fairly extensive, so some may take quite a while to build. Note: All of these by default will be built with the tag latest , i.e. uobflightlabstarling/starling-mavros:latest . This may or may not align with the docker-compose files so please check if errors occur! Building The System \u00b6 Building the core functionality \u00b6 The core functionality is all in the Project Starling Repository: https://github.com/StarlingUAS/ProjectStarling . In your workspace, first clone and navigate into the repository: git clone --depth=1 https://github.com/StarlingUAS/ProjectStarling.git cd ProjectStarling Then lets first build the simulation containers (1 and 2). These can be built using a Makefile in the simulator directory. cd simulator make iris-ap A Makefile is an easy to use format which describes simple commands which can be run using the make comamnd. Here we use it to simplify running the commands to build our system. Once the simulator has been built, we can then build the system components (3, 4, and 5). These can be built using a Makefile in the system directory cd system make mavros make controller-base make rosbridge-suite Building the Fenswood Scenario \u00b6 The Fenswood Scenario container in this repository is built on top of the Ardupilot core gazebo simulator ( uobflightlabstarling/starling-sim-iris-ap ) container we built earlier. Therefore we must make sure we have built it before we continue. Now you can navigate into the FenswoodScenario repository. If you have not yet cloned the repository, please clone it in your local workspace (outside of ProjectStarling). git clone --depth=1 https://github.com/StarlingUAS/FenswoodScenario.git cd FenswoodScenario make The make command above will automatically find the arduipilot core simulator we built previously and include the new parts which make it into the FenswoodScenario simulator. The simulator should now be ready to use during this tutorial, and during the fenswood volcano templates tutorials.","title":"Building From Source"},{"location":"details/building_from_source/#building-fenswood-scenario-and-the-simulator-stack-from-source","text":"This tutorial takes the reader through how to build the simulator stack and the necessary requirements for the Fenswood Project scenario from source. THIS IS RECOMMENDED FOR THOSE RUNNING ON ARM64 ARCHITECTURES This includes the new Mac models running M1 chipsets. Building Fenswood Scenario and the Simulator Stack from Source The System Building The System Building the core functionality Building the Fenswood Scenario","title":"Building Fenswood Scenario and the Simulator Stack from Source"},{"location":"details/building_from_source/#the-system","text":"This repository builds upon the ProjectStarling set of containers and therefore requires the following containers to be built Ardupilot core gazebo simulator ( uobflightlabstarling/starling-sim-iris-ap ) Ardupilot SITL ( uobflightlabstarling/starling-sim-ardupilot-copter ) Mavros ( uobflightlabstarling/starling-mavros ) Rosbridge Suite ( uobflightlabstarling/rosbridge-suite ) Controller Base ( uobflightlabstarling/starling-controller-base ) FenswoodScenario simulator ( uobflightlabstarling/starling-sim-iris-ap ) which is built upon (1) Warning These containers are all fairly extensive, so some may take quite a while to build. Note: All of these by default will be built with the tag latest , i.e. uobflightlabstarling/starling-mavros:latest . This may or may not align with the docker-compose files so please check if errors occur!","title":"The System"},{"location":"details/building_from_source/#building-the-system","text":"","title":"Building The System"},{"location":"details/building_from_source/#building-the-core-functionality","text":"The core functionality is all in the Project Starling Repository: https://github.com/StarlingUAS/ProjectStarling . In your workspace, first clone and navigate into the repository: git clone --depth=1 https://github.com/StarlingUAS/ProjectStarling.git cd ProjectStarling Then lets first build the simulation containers (1 and 2). These can be built using a Makefile in the simulator directory. cd simulator make iris-ap A Makefile is an easy to use format which describes simple commands which can be run using the make comamnd. Here we use it to simplify running the commands to build our system. Once the simulator has been built, we can then build the system components (3, 4, and 5). These can be built using a Makefile in the system directory cd system make mavros make controller-base make rosbridge-suite","title":"Building the core functionality"},{"location":"details/building_from_source/#building-the-fenswood-scenario","text":"The Fenswood Scenario container in this repository is built on top of the Ardupilot core gazebo simulator ( uobflightlabstarling/starling-sim-iris-ap ) container we built earlier. Therefore we must make sure we have built it before we continue. Now you can navigate into the FenswoodScenario repository. If you have not yet cloned the repository, please clone it in your local workspace (outside of ProjectStarling). git clone --depth=1 https://github.com/StarlingUAS/FenswoodScenario.git cd FenswoodScenario make The make command above will automatically find the arduipilot core simulator we built previously and include the new parts which make it into the FenswoodScenario simulator. The simulator should now be ready to use during this tutorial, and during the fenswood volcano templates tutorials.","title":"Building the Fenswood Scenario"},{"location":"details/gimbal/","text":"Drone Gimbal \u00b6 The iris model ( iris_demo ) spawned has access to a one axis pitch only gimbal which can be controlled by giving an absolute angle (in radians). The source code for this gimbal is in the ProjectStarling repository. Using the gimbal \u00b6 The gimbal is controlled using a single Publisher/Subscriber pair /<Vehicle_id>/gimbal_tilt_cmd (std_msgs/msg/Float32): Subscriber takes a topic {\"data: 0.5\"} and moves the gimbal to 0.5 radians down from the horizontal. There exists an onboard P controller to do this. /<vehicle_id>/gimbal_tilt_status (std_msgs/msg/Float32): Publisher which publishes the radian angle of the gimbal","title":"Gimbal Control"},{"location":"details/gimbal/#drone-gimbal","text":"The iris model ( iris_demo ) spawned has access to a one axis pitch only gimbal which can be controlled by giving an absolute angle (in radians). The source code for this gimbal is in the ProjectStarling repository.","title":"Drone Gimbal"},{"location":"details/gimbal/#using-the-gimbal","text":"The gimbal is controlled using a single Publisher/Subscriber pair /<Vehicle_id>/gimbal_tilt_cmd (std_msgs/msg/Float32): Subscriber takes a topic {\"data: 0.5\"} and moves the gimbal to 0.5 radians down from the horizontal. There exists an onboard P controller to do this. /<vehicle_id>/gimbal_tilt_status (std_msgs/msg/Float32): Publisher which publishes the radian angle of the gimbal","title":"Using the gimbal"},{"location":"details/repo_layout/","text":"Fenswood Scenario Repository Layout \u00b6 This document briefly explains the files and folders within this repository. Overview \u00b6 At a high level, this repository generates the starling-sim-iris-ap-fenswood simulation docker container which will start up a gazebo simulation of Fenswood Farm with an Iris quadcopter with an attached payload and a dynamically generated volcano caldera. It contains the following: Contains the world file which describes the fenswood farm environment ( fenswood.world ) Contains the script ( spawn_targets.py ) which dynamically generates the volcano caldera at runtime. Contains the gazebo ros2 plugin which allows for the attachment and detachment of a payload Contains the Dockerfile which compiles all of these into the starling-sim-iris-ap docker container Contains a docker-compose file which will automatically build the simulator without needing to build the container yourself manually Contains the documentation for https://starlinguas.github.io/FenswoodScenario Contains the .github to enable automated builds on github actions. Contains the example controller in example_controller_python_ap . World file \u00b6 In the fenswood/worlds directory, there exist the .world sdf files which specify the layout and objects in the world. This specifyies all of the objects, as well as the GPS coordinates of the origin of the world. To enable attach/detach, there is a second world which includes the attach_vehicles plugin fenswood_with_payload.world . This is enabled by default. The models used are all in the fenswood/models folder. The models which are not included may be in the upstream simulation containers such as starling-sim-iris-ap (e.g. the iris model ( iris_demo )) The fenswood/setup.bash file copies all of the models in. Launching and target spawning \u00b6 The fenswood/iris.launch.xml configuration determins what is being launched. This calls the target spawning script is in fenswood/spawn_targets.py with an example target configuration in fenswood/target . Attaching/detaching payload \u00b6 The simulation/attach_vehicles_plugin contains the Rosnode source for the global gazebo plugin which manages the attaching and detaching of sensor payloads. The payload itself is defined in fenswood/models/sensor_payload/model.sdf and edts should be made there to change it. The fenswood/iris.launch.xml launch file launches both the drone and the payload and attempts to automatically join them on statup. Building \u00b6 There exists a Makefile which should provide automated commands for building and testing the Dockerfile simulator for this repository. Example controller \u00b6 The example controller is in the example_controller_python_ap folder. This is a Python rosnode put into a local Docker container. The docker-compose.example_drone_controller.yaml docker-compose file is used to build and run this controller against the simulator run by docker-compose.yml","title":"Repository Overview"},{"location":"details/repo_layout/#fenswood-scenario-repository-layout","text":"This document briefly explains the files and folders within this repository.","title":"Fenswood Scenario Repository Layout"},{"location":"details/repo_layout/#overview","text":"At a high level, this repository generates the starling-sim-iris-ap-fenswood simulation docker container which will start up a gazebo simulation of Fenswood Farm with an Iris quadcopter with an attached payload and a dynamically generated volcano caldera. It contains the following: Contains the world file which describes the fenswood farm environment ( fenswood.world ) Contains the script ( spawn_targets.py ) which dynamically generates the volcano caldera at runtime. Contains the gazebo ros2 plugin which allows for the attachment and detachment of a payload Contains the Dockerfile which compiles all of these into the starling-sim-iris-ap docker container Contains a docker-compose file which will automatically build the simulator without needing to build the container yourself manually Contains the documentation for https://starlinguas.github.io/FenswoodScenario Contains the .github to enable automated builds on github actions. Contains the example controller in example_controller_python_ap .","title":"Overview"},{"location":"details/repo_layout/#world-file","text":"In the fenswood/worlds directory, there exist the .world sdf files which specify the layout and objects in the world. This specifyies all of the objects, as well as the GPS coordinates of the origin of the world. To enable attach/detach, there is a second world which includes the attach_vehicles plugin fenswood_with_payload.world . This is enabled by default. The models used are all in the fenswood/models folder. The models which are not included may be in the upstream simulation containers such as starling-sim-iris-ap (e.g. the iris model ( iris_demo )) The fenswood/setup.bash file copies all of the models in.","title":"World file"},{"location":"details/repo_layout/#launching-and-target-spawning","text":"The fenswood/iris.launch.xml configuration determins what is being launched. This calls the target spawning script is in fenswood/spawn_targets.py with an example target configuration in fenswood/target .","title":"Launching and target spawning"},{"location":"details/repo_layout/#attachingdetaching-payload","text":"The simulation/attach_vehicles_plugin contains the Rosnode source for the global gazebo plugin which manages the attaching and detaching of sensor payloads. The payload itself is defined in fenswood/models/sensor_payload/model.sdf and edts should be made there to change it. The fenswood/iris.launch.xml launch file launches both the drone and the payload and attempts to automatically join them on statup.","title":"Attaching/detaching payload"},{"location":"details/repo_layout/#building","text":"There exists a Makefile which should provide automated commands for building and testing the Dockerfile simulator for this repository.","title":"Building"},{"location":"details/repo_layout/#example-controller","text":"The example controller is in the example_controller_python_ap folder. This is a Python rosnode put into a local Docker container. The docker-compose.example_drone_controller.yaml docker-compose file is used to build and run this controller against the simulator run by docker-compose.yml","title":"Example controller"},{"location":"details/target_spawning/","text":"Target Spawning \u00b6 For the purpose of the project, a volcano has to be modelled with dynamic areas representing danger around the base. Target spawning is achieved via the spawn_target.py script. It spawns a specified number or yellow target rectangles and red hotspot circles around the 'annulus' of a volcano. The Yellow Target Rectangles represent areas of dangerous terrain where landing would be unsafe (pyroclastic flows etc) The Red Hotspot Circles represent areas of no-flight which would be dangerous (geysers, gas vents etc) Spawning Algorithm \u00b6 There has to be an element of randomness in the spawning. Since the annulus is modelled as a circle, the placement of targets is based on the radial angle theta, on the edge of the annulus. In addition the hotspots should be clustered around each yellow target either on or near them. Here is the process: For each primary target, an angle theta is selected uniformly. For each additional target, random thetas are drawn which satisfy a minimal angle between existing targets (first valid theta chosen). The hotspot locations are then drawn from a normal distribution with a given variance around the targets angle and radial distances to force clustering. Hotspot locations are drawn until valid hotspots which are sufficiently far from each other are found. These locations are then dynamically generated into an sdf XML representing the volcano. Spawning Environment Variable Options \u00b6 The primary options are given by the following: Name Default Value Description SPAWN_TARGET_NUM_TARGETS 2 Number of Yellow Targets being spawned SPAWN_TARGET_NUM_HOTSPOTS 5 Number of Red Targets being spawned SPAWN_TARGET_HOTSPOT_RADIUS 3 Radius of Red circular hotspots SPAWN_TARGET_TARGET_LENGTH 20 Length of yellow target SPAWN_TARGET_TARGET_WIDTH 5 Width of yellow target SPAWN_TARGET_RANDOM_SEED None Random seed for random generation, used for deterministic arrangements. SPAWN_TARGET_FILE_PATH \"\" File Path to fixed spawn, see example file i 'fenswood/target/default_target.json' Change Size and Location of Volcano Annulus (Calculated from GPS positions): Name Default Value Description SPAWN_TARGET_ANNULUS_RADIUS 40 Radius of Volcano SPAWN_TARGET_ANNULUS_LOC_X -195 Location Relative to Spawn/Takeoff Location SPAWN_TARGET_ANNULUS_LOC_Y -163 Location Relative to Spawn/Takeoff Location SPAWN_TARGET_ANNULUS_LOC_Z 0.1 Location Relative to Spawn/Takeoff Location Change Random Spawn Parameters Name Default Value Description SPAWN_TARGET_GEN_TARGET_LOC_ANGLE_MIN -pi/2 Target location generationg minimum angle SPAWN_TARGET_GEN_TARGET_LOC_ANGLE_MAX pi/2 Target location generation maximum angle SPAWN_TARGET_GEN_HOTSPOT_ANGLE_VARIANCE 0.3 Hotspot sampling normal variance for angle variation relative to target centers SPAWN_TARGET_GEN_HOTSPOT_RADIUS_VARIANCE 0.5 Hotspot sampling normal variance for radial variation relative to target centers SPAWN_TARGET_GEN_BETWEEN_TARGET_LOC_ANGLE_MIN pi/3 Minimal angle targets SPAWN_TARGET_GEN_BETWEEN_TARGET_LOC_ANGLE_MAX 4 Maximal distance between hotspots Note that if minimal angle and maximal distance are set incorrectly, it may cause an indefinite sampling as valid samples cannot be generated. Setting variables \u00b6 The variables can be set in the usual manner either in the docker run comamnd or in the docker-compose file. For example, you can create a new docker-compose file that is the same as the current one with the following modification to the simhost container: simhost: image: uobflightlabstarling/starling-sim-iris-ap:${STARLING_RELEASE:-latest} environment: - AP_SITL_HOST=sitl - SPAWN_TARGET_RANDOM_SEED=22 # <- This specifies a random seed - SPAWN_TARGET_GEN_BETWEEN_TARGET_LOC_ANGLE_MAX=8 - SPAWN_TARGET_GEN_HOTSPOT_ANGLE_VARIANCE=0.5 volumes: - ./fenswood:/ros.env.d/fenswood command: [\"ros2\", \"launch\", \"/ros.env.d/fenswood/iris.launch.xml\"] ports: - \"8080:8080\" With the Makefile commands, these can be run like so make run ENV=\"-e SPAWN_TARGET_RANDOM_SEED=22\"","title":"Volcano Target Spawning"},{"location":"details/target_spawning/#target-spawning","text":"For the purpose of the project, a volcano has to be modelled with dynamic areas representing danger around the base. Target spawning is achieved via the spawn_target.py script. It spawns a specified number or yellow target rectangles and red hotspot circles around the 'annulus' of a volcano. The Yellow Target Rectangles represent areas of dangerous terrain where landing would be unsafe (pyroclastic flows etc) The Red Hotspot Circles represent areas of no-flight which would be dangerous (geysers, gas vents etc)","title":"Target Spawning"},{"location":"details/target_spawning/#spawning-algorithm","text":"There has to be an element of randomness in the spawning. Since the annulus is modelled as a circle, the placement of targets is based on the radial angle theta, on the edge of the annulus. In addition the hotspots should be clustered around each yellow target either on or near them. Here is the process: For each primary target, an angle theta is selected uniformly. For each additional target, random thetas are drawn which satisfy a minimal angle between existing targets (first valid theta chosen). The hotspot locations are then drawn from a normal distribution with a given variance around the targets angle and radial distances to force clustering. Hotspot locations are drawn until valid hotspots which are sufficiently far from each other are found. These locations are then dynamically generated into an sdf XML representing the volcano.","title":"Spawning Algorithm"},{"location":"details/target_spawning/#spawning-environment-variable-options","text":"The primary options are given by the following: Name Default Value Description SPAWN_TARGET_NUM_TARGETS 2 Number of Yellow Targets being spawned SPAWN_TARGET_NUM_HOTSPOTS 5 Number of Red Targets being spawned SPAWN_TARGET_HOTSPOT_RADIUS 3 Radius of Red circular hotspots SPAWN_TARGET_TARGET_LENGTH 20 Length of yellow target SPAWN_TARGET_TARGET_WIDTH 5 Width of yellow target SPAWN_TARGET_RANDOM_SEED None Random seed for random generation, used for deterministic arrangements. SPAWN_TARGET_FILE_PATH \"\" File Path to fixed spawn, see example file i 'fenswood/target/default_target.json' Change Size and Location of Volcano Annulus (Calculated from GPS positions): Name Default Value Description SPAWN_TARGET_ANNULUS_RADIUS 40 Radius of Volcano SPAWN_TARGET_ANNULUS_LOC_X -195 Location Relative to Spawn/Takeoff Location SPAWN_TARGET_ANNULUS_LOC_Y -163 Location Relative to Spawn/Takeoff Location SPAWN_TARGET_ANNULUS_LOC_Z 0.1 Location Relative to Spawn/Takeoff Location Change Random Spawn Parameters Name Default Value Description SPAWN_TARGET_GEN_TARGET_LOC_ANGLE_MIN -pi/2 Target location generationg minimum angle SPAWN_TARGET_GEN_TARGET_LOC_ANGLE_MAX pi/2 Target location generation maximum angle SPAWN_TARGET_GEN_HOTSPOT_ANGLE_VARIANCE 0.3 Hotspot sampling normal variance for angle variation relative to target centers SPAWN_TARGET_GEN_HOTSPOT_RADIUS_VARIANCE 0.5 Hotspot sampling normal variance for radial variation relative to target centers SPAWN_TARGET_GEN_BETWEEN_TARGET_LOC_ANGLE_MIN pi/3 Minimal angle targets SPAWN_TARGET_GEN_BETWEEN_TARGET_LOC_ANGLE_MAX 4 Maximal distance between hotspots Note that if minimal angle and maximal distance are set incorrectly, it may cause an indefinite sampling as valid samples cannot be generated.","title":"Spawning Environment Variable Options"},{"location":"details/target_spawning/#setting-variables","text":"The variables can be set in the usual manner either in the docker run comamnd or in the docker-compose file. For example, you can create a new docker-compose file that is the same as the current one with the following modification to the simhost container: simhost: image: uobflightlabstarling/starling-sim-iris-ap:${STARLING_RELEASE:-latest} environment: - AP_SITL_HOST=sitl - SPAWN_TARGET_RANDOM_SEED=22 # <- This specifies a random seed - SPAWN_TARGET_GEN_BETWEEN_TARGET_LOC_ANGLE_MAX=8 - SPAWN_TARGET_GEN_HOTSPOT_ANGLE_VARIANCE=0.5 volumes: - ./fenswood:/ros.env.d/fenswood command: [\"ros2\", \"launch\", \"/ros.env.d/fenswood/iris.launch.xml\"] ports: - \"8080:8080\" With the Makefile commands, these can be run like so make run ENV=\"-e SPAWN_TARGET_RANDOM_SEED=22\"","title":"Setting variables"},{"location":"tutorials/inspecting/","text":"Inspecting and Debugging Starling with Docker and ROS \u00b6 Now we have the full example Fenswood Scenario running, we can start to inspect what's going on a bit more! This will be more useful when developing your own controller, but this will give you an idea of whether your systems are working or not. Inspecting Docker \u00b6 As you will hopefully be aware now, there's a fair amount going on under the hood! Because of all of these pieces which need to fit together, occasionally things fail, and therefore you will need to be able to inspect whats going on. As most of Starling relys on using Docker we can use some of the docker commands to inspect what is going on! It is useful to know what docker containers exist locally on your system and whether they are the most recent release. The following command will list your local docker containers images and when they were last released myuser@my-machine:~$ docker images uobflightlabstarling/starling-sim-iris-ap latest 02ba82372286 6 weeks ago 5.07GB uobflightlabstarling/starling-sim-iris <none> 826dab23768b 6 weeks ago 5.84GB uobflightlabstarling/starling-sim-ardupilot-gazebo latest df39b5d0181e 6 weeks ago 5.05GB uobflightlabstarling/starling-sim-ardupilot-copter <none> 6a10c0c95714 6 weeks ago 2.35GB uobflightlabstarling/starling-mavros <none> 3a5142abfc0c 6 weeks ago 2.04GB uobflightlabstarling/rosbridge-suite latest 97a05ece1aa3 6 weeks ago 887MB uobflightlabstarling/starling-ui-example latest 83e9a37ddbdf 6 weeks ago 1.33GB To see what containers are running, you can use the following. When running Fenswood you should see 5 containers running. myuser@my-machine:~$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES dfea0bbf9b69 uobflightlabstarling/starling-ui-example \"/ros_entrypoint.sh \u2026\" 3 hours ago Up 9 minutes fenswoodscenario_ui-example_1 1b72f667a557 uobflightlabstarling/starling-mavros:latest \"/ros_entrypoint.sh \u2026\" 3 hours ago Up 9 minutes fenswoodscenario_mavros_1 9d55eb4de60e uobflightlabstarling/rosbridge-suite:latest \"/ros_entrypoint.sh \u2026\" 3 hours ago Up 9 minutes fenswoodscenario_rosbridge-suite_1 5205bcf5495f example_python_controller_controller \"/ros_entrypoint.sh \u2026\" 3 weeks ago Up 8 minutes example_python_controller_controller_1 9fa66d47e21e uobflightlabstarling/starling-sim-ardupilot-copter:latest \"/home/root/entrypoi\u2026\" 4 weeks ago Up 9 minutes fenswoodscenario_sitl_1 e5e47cc36ec1 uobflightlabstarling/starling-sim-iris-ap:latest \"/ros_entrypoint.sh \u2026\" 5 weeks ago Up 9 minutes fenswoodscenario_simhost_1 When running docker ps, it shows some useful information. You can use this information to inspect the inside of a container. Now what do we mean by the 'inside of a container'. Essentially the container allows us to run a pre-set set of instructions inside a blank mini version of linux. When we are debugging, it is sometimes really useful to have a look at what is going on inside this mini version of linux! The exec command allows us to go inside one of these containers to make changes directly. Note that when we are inside, we are no longer in your own version of the desktop, and that changes made are persistent inside the container! When inside the container, you can run some of the ROS2 comamnds in the next section. docker exec -it <container id> bash e.g. myuser@my-machine:~$ docker exec -it 1b72f667a557 bash root@my-machine:/ros_ws# If a particular docker container is not working properly, you can also kill a container: docker kill <container id> Inspecting ROS2 \u00b6 As mentioned before, everything in starling is running ROS2. Therefore all of the ROS2 nodes, topics and services can be inspected and observed. We can do this inspection using the following few commands. First ensure that you have docker exec into any of the containers. For example using the container id of the container labelled starling-mavros . Once you are inside, you first need to run the following to enable ROS2 commands. ( Tab autocompleting is available) root@my-machine:~$ source /opt/ros/foxy/setup.bash The first thing you can do is list all of the ROS2 nodes in the network node command: root@my-machine:~$ ros2 node list WARNING: Be aware that are nodes in the graph that share an exact name, this can have unintended side effects. /gazebo /rosapi /rosapi /rosbridge_websocket /vehicle_1/camera_controller /vehicle_1/example_controller /vehicle_1/gimbal_small_2d /vehicle_1/ros_bridge This will show a list of all the nodes that ROS2 can find. You should see all of the nodes from the simulator and the example controller. Then, we can inspect the list of available topics using the topic command. root@my-machine:~$ ros2 topic list /client_count /clock /connected_clients /emergency_stop /mission_start /parameter_events /performance_metrics /rosout /vehicle_1/camera/camera_info /vehicle_1/camera/image_raw /vehicle_1/camera/image_raw/compressed /vehicle_1/camera/image_raw/compressedDepth /vehicle_1/camera/image_raw/theora /vehicle_1/gimbal_tilt_cmd /vehicle_1/gimbal_tilt_status /vehicle_1/mavlink/from /vehicle_1/mavlink/to /vehicle_1/mavros/battery /vehicle_1/mavros/distance_sensor/hrlv_ez4_sonar /vehicle_1/mavros/distance_sensor/lidarlite_laser /vehicle_1/mavros/distance_sensor/rangefinder /vehicle_1/mavros/distance_sensor/temperature /vehicle_1/mavros/global_position/global /vehicle_1/mavros/global_position/velocity /vehicle_1/mavros/image/camera_image /vehicle_1/mavros/local_position/pose /vehicle_1/mavros/manual_control/control /vehicle_1/mavros/manual_control/send /vehicle_1/mavros/mission/reached /vehicle_1/mavros/mission/waypoints /vehicle_1/mavros/px4flow/ground_distance /vehicle_1/mavros/px4flow/raw/optical_flow_rad /vehicle_1/mavros/safety_area /vehicle_1/mavros/setpoint_accel/accel /vehicle_1/mavros/setpoint_attitude/attitude /vehicle_1/mavros/setpoint_attitude/cmd_vel /vehicle_1/mavros/setpoint_attitude/thrust /vehicle_1/mavros/setpoint_position/global /vehicle_1/mavros/setpoint_position/global_to_local /vehicle_1/mavros/setpoint_position/local /vehicle_1/mavros/setpoint_raw/attitude /vehicle_1/mavros/setpoint_raw/global /vehicle_1/mavros/setpoint_raw/local /vehicle_1/mavros/setpoint_velocity/cmd_vel_unstamped /vehicle_1/mavros/state /vehicle_1/mavros/vision_pose/pose /vehicle_1/mavros/vision_pose/pose_cov /vehicle_1/mavros/vision_speed/speed_twist /vehicle_1/mavros/vision_speed/speed_vector If there is a particular topic you want to inspect, you can use the echo command of topic , for example if we wanted to inspect the topic /vehicle_1/mavros/state we can run: root@my-machine:~$ ros2 topic echo /vehicle_1/mavros/state header: stamp: sec: 1639423734 nanosec: 393874329 frame_id: '' connected: true armed: false guided: true manual_input: true mode: GUIDED system_status: 3 --- header: stamp: sec: 1639423735 nanosec: 435107761 frame_id: '' connected: true armed: false guided: true manual_input: true mode: GUIDED system_status: 3 --- ^C Note: Press Ctrl + C to stop the echo stream This should (assuming the connection to all of the other elements is working) start printing out the current state of the drone. Including whether it is armed or not, and which mode it is currently in. Finally, you can also inspect the services on the network using the service command like the following: root@my-machine:~$ ros2 service list ... /unpause_physics /vehicle_1/camera_controller/describe_parameters /vehicle_1/camera_controller/get_parameter_types /vehicle_1/camera_controller/get_parameters /vehicle_1/camera_controller/list_parameters /vehicle_1/camera_controller/set_parameters /vehicle_1/camera_controller/set_parameters_atomically /vehicle_1/example_controller/describe_parameters /vehicle_1/example_controller/get_parameter_types /vehicle_1/example_controller/get_parameters /vehicle_1/example_controller/list_parameters /vehicle_1/example_controller/set_parameters /vehicle_1/example_controller/set_parameters_atomically /vehicle_1/gimbal_small_2d/describe_parameters /vehicle_1/gimbal_small_2d/get_parameter_types /vehicle_1/gimbal_small_2d/get_parameters /vehicle_1/gimbal_small_2d/list_parameters /vehicle_1/gimbal_small_2d/set_parameters /vehicle_1/gimbal_small_2d/set_parameters_atomically /vehicle_1/mavros/cmd/arming /vehicle_1/mavros/cmd/command /vehicle_1/mavros/cmd/command_int /vehicle_1/mavros/cmd/land /vehicle_1/mavros/cmd/set_home /vehicle_1/mavros/cmd/takeoff /vehicle_1/mavros/cmd/trigger_control /vehicle_1/mavros/mission/clear /vehicle_1/mavros/mission/pull /vehicle_1/mavros/mission/push /vehicle_1/mavros/mission/set_current /vehicle_1/mavros/set_mode /vehicle_1/mavros/set_stream_rate /vehicle_1/ros_bridge/describe_parameters /vehicle_1/ros_bridge/get_parameter_types /vehicle_1/ros_bridge/get_parameters /vehicle_1/ros_bridge/list_parameters /vehicle_1/ros_bridge/set_parameters /vehicle_1/ros_bridge/set_parameters_atomically /vehicle_1/set_camera_info","title":"6. Inspecting and Debugging Starling with Docker and ROS"},{"location":"tutorials/inspecting/#inspecting-and-debugging-starling-with-docker-and-ros","text":"Now we have the full example Fenswood Scenario running, we can start to inspect what's going on a bit more! This will be more useful when developing your own controller, but this will give you an idea of whether your systems are working or not.","title":"Inspecting and Debugging Starling with Docker and ROS"},{"location":"tutorials/inspecting/#inspecting-docker","text":"As you will hopefully be aware now, there's a fair amount going on under the hood! Because of all of these pieces which need to fit together, occasionally things fail, and therefore you will need to be able to inspect whats going on. As most of Starling relys on using Docker we can use some of the docker commands to inspect what is going on! It is useful to know what docker containers exist locally on your system and whether they are the most recent release. The following command will list your local docker containers images and when they were last released myuser@my-machine:~$ docker images uobflightlabstarling/starling-sim-iris-ap latest 02ba82372286 6 weeks ago 5.07GB uobflightlabstarling/starling-sim-iris <none> 826dab23768b 6 weeks ago 5.84GB uobflightlabstarling/starling-sim-ardupilot-gazebo latest df39b5d0181e 6 weeks ago 5.05GB uobflightlabstarling/starling-sim-ardupilot-copter <none> 6a10c0c95714 6 weeks ago 2.35GB uobflightlabstarling/starling-mavros <none> 3a5142abfc0c 6 weeks ago 2.04GB uobflightlabstarling/rosbridge-suite latest 97a05ece1aa3 6 weeks ago 887MB uobflightlabstarling/starling-ui-example latest 83e9a37ddbdf 6 weeks ago 1.33GB To see what containers are running, you can use the following. When running Fenswood you should see 5 containers running. myuser@my-machine:~$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES dfea0bbf9b69 uobflightlabstarling/starling-ui-example \"/ros_entrypoint.sh \u2026\" 3 hours ago Up 9 minutes fenswoodscenario_ui-example_1 1b72f667a557 uobflightlabstarling/starling-mavros:latest \"/ros_entrypoint.sh \u2026\" 3 hours ago Up 9 minutes fenswoodscenario_mavros_1 9d55eb4de60e uobflightlabstarling/rosbridge-suite:latest \"/ros_entrypoint.sh \u2026\" 3 hours ago Up 9 minutes fenswoodscenario_rosbridge-suite_1 5205bcf5495f example_python_controller_controller \"/ros_entrypoint.sh \u2026\" 3 weeks ago Up 8 minutes example_python_controller_controller_1 9fa66d47e21e uobflightlabstarling/starling-sim-ardupilot-copter:latest \"/home/root/entrypoi\u2026\" 4 weeks ago Up 9 minutes fenswoodscenario_sitl_1 e5e47cc36ec1 uobflightlabstarling/starling-sim-iris-ap:latest \"/ros_entrypoint.sh \u2026\" 5 weeks ago Up 9 minutes fenswoodscenario_simhost_1 When running docker ps, it shows some useful information. You can use this information to inspect the inside of a container. Now what do we mean by the 'inside of a container'. Essentially the container allows us to run a pre-set set of instructions inside a blank mini version of linux. When we are debugging, it is sometimes really useful to have a look at what is going on inside this mini version of linux! The exec command allows us to go inside one of these containers to make changes directly. Note that when we are inside, we are no longer in your own version of the desktop, and that changes made are persistent inside the container! When inside the container, you can run some of the ROS2 comamnds in the next section. docker exec -it <container id> bash e.g. myuser@my-machine:~$ docker exec -it 1b72f667a557 bash root@my-machine:/ros_ws# If a particular docker container is not working properly, you can also kill a container: docker kill <container id>","title":"Inspecting Docker"},{"location":"tutorials/inspecting/#inspecting-ros2","text":"As mentioned before, everything in starling is running ROS2. Therefore all of the ROS2 nodes, topics and services can be inspected and observed. We can do this inspection using the following few commands. First ensure that you have docker exec into any of the containers. For example using the container id of the container labelled starling-mavros . Once you are inside, you first need to run the following to enable ROS2 commands. ( Tab autocompleting is available) root@my-machine:~$ source /opt/ros/foxy/setup.bash The first thing you can do is list all of the ROS2 nodes in the network node command: root@my-machine:~$ ros2 node list WARNING: Be aware that are nodes in the graph that share an exact name, this can have unintended side effects. /gazebo /rosapi /rosapi /rosbridge_websocket /vehicle_1/camera_controller /vehicle_1/example_controller /vehicle_1/gimbal_small_2d /vehicle_1/ros_bridge This will show a list of all the nodes that ROS2 can find. You should see all of the nodes from the simulator and the example controller. Then, we can inspect the list of available topics using the topic command. root@my-machine:~$ ros2 topic list /client_count /clock /connected_clients /emergency_stop /mission_start /parameter_events /performance_metrics /rosout /vehicle_1/camera/camera_info /vehicle_1/camera/image_raw /vehicle_1/camera/image_raw/compressed /vehicle_1/camera/image_raw/compressedDepth /vehicle_1/camera/image_raw/theora /vehicle_1/gimbal_tilt_cmd /vehicle_1/gimbal_tilt_status /vehicle_1/mavlink/from /vehicle_1/mavlink/to /vehicle_1/mavros/battery /vehicle_1/mavros/distance_sensor/hrlv_ez4_sonar /vehicle_1/mavros/distance_sensor/lidarlite_laser /vehicle_1/mavros/distance_sensor/rangefinder /vehicle_1/mavros/distance_sensor/temperature /vehicle_1/mavros/global_position/global /vehicle_1/mavros/global_position/velocity /vehicle_1/mavros/image/camera_image /vehicle_1/mavros/local_position/pose /vehicle_1/mavros/manual_control/control /vehicle_1/mavros/manual_control/send /vehicle_1/mavros/mission/reached /vehicle_1/mavros/mission/waypoints /vehicle_1/mavros/px4flow/ground_distance /vehicle_1/mavros/px4flow/raw/optical_flow_rad /vehicle_1/mavros/safety_area /vehicle_1/mavros/setpoint_accel/accel /vehicle_1/mavros/setpoint_attitude/attitude /vehicle_1/mavros/setpoint_attitude/cmd_vel /vehicle_1/mavros/setpoint_attitude/thrust /vehicle_1/mavros/setpoint_position/global /vehicle_1/mavros/setpoint_position/global_to_local /vehicle_1/mavros/setpoint_position/local /vehicle_1/mavros/setpoint_raw/attitude /vehicle_1/mavros/setpoint_raw/global /vehicle_1/mavros/setpoint_raw/local /vehicle_1/mavros/setpoint_velocity/cmd_vel_unstamped /vehicle_1/mavros/state /vehicle_1/mavros/vision_pose/pose /vehicle_1/mavros/vision_pose/pose_cov /vehicle_1/mavros/vision_speed/speed_twist /vehicle_1/mavros/vision_speed/speed_vector If there is a particular topic you want to inspect, you can use the echo command of topic , for example if we wanted to inspect the topic /vehicle_1/mavros/state we can run: root@my-machine:~$ ros2 topic echo /vehicle_1/mavros/state header: stamp: sec: 1639423734 nanosec: 393874329 frame_id: '' connected: true armed: false guided: true manual_input: true mode: GUIDED system_status: 3 --- header: stamp: sec: 1639423735 nanosec: 435107761 frame_id: '' connected: true armed: false guided: true manual_input: true mode: GUIDED system_status: 3 --- ^C Note: Press Ctrl + C to stop the echo stream This should (assuming the connection to all of the other elements is working) start printing out the current state of the drone. Including whether it is armed or not, and which mode it is currently in. Finally, you can also inspect the services on the network using the service command like the following: root@my-machine:~$ ros2 service list ... /unpause_physics /vehicle_1/camera_controller/describe_parameters /vehicle_1/camera_controller/get_parameter_types /vehicle_1/camera_controller/get_parameters /vehicle_1/camera_controller/list_parameters /vehicle_1/camera_controller/set_parameters /vehicle_1/camera_controller/set_parameters_atomically /vehicle_1/example_controller/describe_parameters /vehicle_1/example_controller/get_parameter_types /vehicle_1/example_controller/get_parameters /vehicle_1/example_controller/list_parameters /vehicle_1/example_controller/set_parameters /vehicle_1/example_controller/set_parameters_atomically /vehicle_1/gimbal_small_2d/describe_parameters /vehicle_1/gimbal_small_2d/get_parameter_types /vehicle_1/gimbal_small_2d/get_parameters /vehicle_1/gimbal_small_2d/list_parameters /vehicle_1/gimbal_small_2d/set_parameters /vehicle_1/gimbal_small_2d/set_parameters_atomically /vehicle_1/mavros/cmd/arming /vehicle_1/mavros/cmd/command /vehicle_1/mavros/cmd/command_int /vehicle_1/mavros/cmd/land /vehicle_1/mavros/cmd/set_home /vehicle_1/mavros/cmd/takeoff /vehicle_1/mavros/cmd/trigger_control /vehicle_1/mavros/mission/clear /vehicle_1/mavros/mission/pull /vehicle_1/mavros/mission/push /vehicle_1/mavros/mission/set_current /vehicle_1/mavros/set_mode /vehicle_1/mavros/set_stream_rate /vehicle_1/ros_bridge/describe_parameters /vehicle_1/ros_bridge/get_parameter_types /vehicle_1/ros_bridge/get_parameters /vehicle_1/ros_bridge/list_parameters /vehicle_1/ros_bridge/set_parameters /vehicle_1/ros_bridge/set_parameters_atomically /vehicle_1/set_camera_info","title":"Inspecting ROS2"},{"location":"tutorials/intro_to_linux/","text":"A Brief Introduction to Linux \u00b6 Adapted from this digital ocean tutorial What is Linux \u00b6 Linux is a family of free and open-source operating systems based on the Linux kernel (core operating system). Operating systems based on Linux are known as Linux distributions or distros. Examples include Debian, Ubuntu, Fedora, CentOS, Gentoo, Arch Linux, and many others. The Linux kernel has been under active development since 1991, and has proven to be extremely versatile and adaptable. You can find computers that run Linux in a wide variety of contexts all over the world, from web servers to cell phones. Today, 90% of all cloud infrastructure and 74% of the world\u2019s smartphones are powered by Linux. However, newcomers to Linux may find it somewhat difficult to approach, as Linux filesystems have a different structure than those found on Windows or MacOS. Additionally, Linux-based operating systems depend heavily on working with the command line interface, while most personal computers rely on graphical interfaces. The Terminal \u00b6 The terms \u201cterminal,\u201d \u201cshell,\u201d and \u201ccommand line interface\u201d are often used interchangeably, but there are subtle differences between them: A terminal is an input and output environment that presents a text-only window running a shell. A shell is a program that exposes the computer\u2019s operating system to a user or program. In Linux systems, the shell presented in a terminal is a command line interpreter. The default shell in Ubuntu Linux is known as bash . A command line interface is a user interface (managed by a command line interpreter program) which processes commands to a computer program and outputs the results. When someone refers to one of these three terms in the context of Linux, they generally mean a terminal environment where you can run commands and see the results printed out to the terminal, such as this: There are two ways to open a terminal: Pressing the Win or Cmd key to open the program menu and typing terminal , then pressing Enter Pressing Ctrl + Alt + T This default terminal is known as the 'gnome-terminal'. Other terminals exist such as 'terminator' Becoming a Linux user requires you to be comfortable with using a terminal. Any administrative task, including file manipulation, package installation, and user management, can be accomplished through the terminal. The terminal is interactive: you specify commands to run (after the $ sign) and the terminal outputs the results of those commands. To execute any command, you type it into the prompt and press Enter . When using the Starling system, interacting with Docker and ROS2, you'll most often be doing so through a terminal shell. Although personal computers that run Linux often come with the kind of graphical desktop environment familiar to most computer users, it is often more efficient or practical to perform certain tasks through commands entered into the terminal. As of writing, a GUI (Graphical User Interface) has not been developed for Starling, and so almost all tasks have to be achieved through the terminal shell. A basic command to try out is echo , which will print things to the terminal. For example echo hello-world will print hello-world into the terminal. You can also use it to observe the value of Environment Variables which record and keep useful variables to the operation of the Operating System. For example, when you run a command in bash , bash will look for the command executable in the locations provided by the environment variable PATH . You can print the contents of this env-var using echo $PATH . The $ before the name of the variable tells bash that the following word represents an environment variable, and that it should be looked up. Navigating the file system \u00b6 Like Windows and Mac, the Linux filesystems are based on a directory tree. This means that you can create directories (which are functionally identical to folders found in other operating systems) inside other directories, and files can exist in any directory. The forward slash ( / ) is used to indicate the root directory in the filesystem hierarchy. When a user logs in to the shell, they are brought to their own user directory, stored within /home/<username> . This is referred to as the user\u2019s home directory. Often you may see the tilde ( ~ ) character when specifying a file location (e.g. ~/Documents/hello.txt = /home/<username>/Documents/hello.txt ). This is shorthand for the user's home directory and gets substituted in when used. To see what directory you are currently active in you can run the pwd command, which stands for \u201cprint working directory\u201d myuser@my-machine:~$ pwd /home/myuser To see a list of files and directories that exist in your current working directory, run the ls command: myuser@my-machine:~$ ls Desktop Documents Downloads Pictures Public Wallpapers You can get more details if you run ls -al command: myuser@my-machine:~$ ls -al drwxr-xr-x 2 myuser myuser 4096 Apr 30 2021 Desktop drwxrwxr-x 8 myuser myuser 4096 Oct 29 09:27 Documents drwxrwxr-x 8 myuser myuser 4096 Dec 10 14:41 Downloads drwxrwxr-x 8 myuser myuser 4096 May 23 10:43 Pictures drwxrwxr-x 8 myuser myuser 4096 Jan 19 2017 Public drwxrwxr-x 8 myuser myuser 4096 Oct 15 09:43 Wallpapers You can create one or more new directories within your current working directory with the mkdir command, which stands for \u201cmake directory\u201d. For example, to create two new directories named testdir1 and testdir2, you might run the first command. You can create nested directories by using the -p option: myuser@my-machine:~$ mkdir testdir1 testdir2 myuser@my-machine:~$ mkdir -p testdir3/testsubdir To navigate into one of these new directories, run the cd command (which stands for \u201cchange directory\u201d) and specify the directory\u2019s name: myuser@my-machine:~$ cd testdir1 myuser@my-machine:~/testdir1$ Note that you can navigate from anywhere to anywhere. cd only requires a valid filepath. Note also that . represents the current folder and .. represents the parent folder. Note also how is shows the current working directory in the shell as well. cd # This will bring you back to home directory cd testdir3/testsubdir # Brings you into testsubdir cd ../ # Brings you back out one level into testdir3 cd ../testdir1 # Brings you back out one level and back into testdir1 cd /home/<username>/testdir2 # Absolute reference to testdir2 cd ~/testdir2 # Absolute reference using tilde to testdir2 Working with files \u00b6 You cannot use cd to interact with files; cd stands for \u201cchange directory\u201d, and only allows you to navigate directories. You can, however, create, edit, and view the contents of files. One way to create a file is with the touch command. This creates an empty file in your current working directory. To create a new file called file.txt: touch file.txt If you decide to rename file.txt later on, you can do so with the mv command. mv stands for \u201cmove\u201d and it can move a file or directory from one place to another. By specifying the original file, file.txt, you can \u201cmove\u201d it to a new location in the current working directory, thereby renaming it. mv file.txt newfile.txt It is also possible to copy a file to a new location with the cp command. If we want to copy newfile.txt, you can make a copy of newfile.txt named newfile_copy.txt like this: cp newfile.txt newfile_copy.txt However, files are not of much use if they don\u2019t contain anything. To edit files, a file editor is necessary. There are many options for file editors, all created by professionals for daily use. Such editors include vim, emacs, nano, and pico. nano is a suitable option for beginners: it is relatively user-friendly and doesn\u2019t overload you with cryptic options or commands. nano file.txt This will open a space where you can start typing to edit the file. In nano specifically you can save your written text by pressing Ctrl + X , Y , and then Enter . This returns you to the shell with a newly saved file.txt . Now that file.txt has some text within it, you can view it using cat or less . The cat command prints the contents of a specified file to your system\u2019s output. Try running cat and pass the file.txt file you just edited as an argument: cat file.txt Using cat to view file contents can be unwieldy and difficult to read if the file is particularly long. As an alternative, you can use the less command which will allow you to paginate the output. Use less to view the contents of the file.txt file, like this: less file.txt This will also print the contents of file.txt, but one terminal page at a time beginning at the start of the file. You can use the spacebar to advance a page, or the arrow keys to go up and down one line at a time. Press Q to quit out of less . Finally, to delete the file.txt file, pass the name of the file as an argument to rm : rm file.txt rm -d directory rmidr directory rm -r directory # If the directory you are deleting is not empty NOTE : If your question has to do with a specific Linux command, the manual pages offer detailed and insightful documentation for nearly every command. To see the man page for any command, pass the command\u2019s name as an argument to the man command - man command . For instance, man rm displays the purpose of rm , how to use it, what options are available, examples of use, and more useful information. NOTE : If a command fails or is hanging or you just want to stop it, most of the time you can stop the running process by pressing Ctrl + C . This will send a Keyboard Interrupt message to the program and hopefully stop it. Connecting the laptop to the Internet (Eduroam) \u00b6 For University of Bristol students connecting to Eduroam see theese instructions Installing Dependencies and Useful Programs \u00b6 Like windows and mac, individual programs can be manually downloaded (usually as a tar.gz file instead of exe ) and manually installed into your operating system (using dpkg ). However, the linux project offers a much more straight forward method through the apt (Advanced Packaging Tool) utility. apt is a free-software user interface that works with core libraries to handle the installation and removal of software on Debian operating systems like Ubuntu. (For other distributions you may come across equivalents like yum ). This is the primary method for installing software onto your system. To use apt , and more specifically apt-get which 'gets' programs for you, you must first run the update command to get the current list of all available software. Note that because sudo is used, you will most likely need to input your password. sudo will be explained below. sudo apt-get update Note that it will hang (stop responding) or fail if you are not connected to the internet. Installing Git and VSCode \u00b6 You can then install your programs using apt-get install . For Starling, you will need to use the git version control software to both download Starling and eventually build your own controllers. To install git , run the following: sudo apt-get install git We also recommend the use of Visual Studio Code as your development environment or text editor, but you are free to use whatever you want (atom, notepad++ etc etc). We heavily make use of it during development and recommend a number of extensions. VScode can be installed using the snap utility. snap is a slightly more modern successor to apt for more general programs. snap comes ready installed on your linux distrubtion. sudo snap install code --classic sudo \u00b6 Now in these commands, we have prefixed all of them with sudo . sudo these days usually stands for superuser do and allows a command to be run with the privileges of the superuser (aka the root user), if the user has been given permissions to do so. Any command which installs or modifies directories outside of the users home directory will often need superuser privileges to avoid non-superusers from changing things they shouldn't. As the above commands all seek to install programs to the system, they need superuser permissions to do so. Running without sudo will give you a permission error. Running a command with sudo will ask you for your own accounts password. Installing Docker \u00b6 For Linux systems, see the following install page . There are multiple ways of installation docker, but we recommend installing using the repository method: Update the apt repository and install requirements sudo apt-get update sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg \\ lsb-release Add Docker's official GPG key: curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg Add Docker's repository: echo \\ \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null Install Docker (and docker-compose!): sudo apt-get update sudo apt-get install docker-ce docker-ce-cli docker-compose containerd.io Test Docker installation: sudo docker run hello-world This will install Docker, accessible using sudo root privileges only. To use docker without sudo, run the following (there are security issues with this, but it doesn't matter for running Starling locally) Run the following sudo groupadd docker sudo usermod -aG docker $USER Log out and log in again to enforce changes Verify that it was successful (we will come back to this command): docker run hello-world That is Docker on Linux installed. See the original page for any further details.","title":"1. A Brief Introduction to Linux"},{"location":"tutorials/intro_to_linux/#a-brief-introduction-to-linux","text":"Adapted from this digital ocean tutorial","title":"A Brief Introduction to Linux"},{"location":"tutorials/intro_to_linux/#what-is-linux","text":"Linux is a family of free and open-source operating systems based on the Linux kernel (core operating system). Operating systems based on Linux are known as Linux distributions or distros. Examples include Debian, Ubuntu, Fedora, CentOS, Gentoo, Arch Linux, and many others. The Linux kernel has been under active development since 1991, and has proven to be extremely versatile and adaptable. You can find computers that run Linux in a wide variety of contexts all over the world, from web servers to cell phones. Today, 90% of all cloud infrastructure and 74% of the world\u2019s smartphones are powered by Linux. However, newcomers to Linux may find it somewhat difficult to approach, as Linux filesystems have a different structure than those found on Windows or MacOS. Additionally, Linux-based operating systems depend heavily on working with the command line interface, while most personal computers rely on graphical interfaces.","title":"What is Linux"},{"location":"tutorials/intro_to_linux/#the-terminal","text":"The terms \u201cterminal,\u201d \u201cshell,\u201d and \u201ccommand line interface\u201d are often used interchangeably, but there are subtle differences between them: A terminal is an input and output environment that presents a text-only window running a shell. A shell is a program that exposes the computer\u2019s operating system to a user or program. In Linux systems, the shell presented in a terminal is a command line interpreter. The default shell in Ubuntu Linux is known as bash . A command line interface is a user interface (managed by a command line interpreter program) which processes commands to a computer program and outputs the results. When someone refers to one of these three terms in the context of Linux, they generally mean a terminal environment where you can run commands and see the results printed out to the terminal, such as this: There are two ways to open a terminal: Pressing the Win or Cmd key to open the program menu and typing terminal , then pressing Enter Pressing Ctrl + Alt + T This default terminal is known as the 'gnome-terminal'. Other terminals exist such as 'terminator' Becoming a Linux user requires you to be comfortable with using a terminal. Any administrative task, including file manipulation, package installation, and user management, can be accomplished through the terminal. The terminal is interactive: you specify commands to run (after the $ sign) and the terminal outputs the results of those commands. To execute any command, you type it into the prompt and press Enter . When using the Starling system, interacting with Docker and ROS2, you'll most often be doing so through a terminal shell. Although personal computers that run Linux often come with the kind of graphical desktop environment familiar to most computer users, it is often more efficient or practical to perform certain tasks through commands entered into the terminal. As of writing, a GUI (Graphical User Interface) has not been developed for Starling, and so almost all tasks have to be achieved through the terminal shell. A basic command to try out is echo , which will print things to the terminal. For example echo hello-world will print hello-world into the terminal. You can also use it to observe the value of Environment Variables which record and keep useful variables to the operation of the Operating System. For example, when you run a command in bash , bash will look for the command executable in the locations provided by the environment variable PATH . You can print the contents of this env-var using echo $PATH . The $ before the name of the variable tells bash that the following word represents an environment variable, and that it should be looked up.","title":"The Terminal"},{"location":"tutorials/intro_to_linux/#navigating-the-file-system","text":"Like Windows and Mac, the Linux filesystems are based on a directory tree. This means that you can create directories (which are functionally identical to folders found in other operating systems) inside other directories, and files can exist in any directory. The forward slash ( / ) is used to indicate the root directory in the filesystem hierarchy. When a user logs in to the shell, they are brought to their own user directory, stored within /home/<username> . This is referred to as the user\u2019s home directory. Often you may see the tilde ( ~ ) character when specifying a file location (e.g. ~/Documents/hello.txt = /home/<username>/Documents/hello.txt ). This is shorthand for the user's home directory and gets substituted in when used. To see what directory you are currently active in you can run the pwd command, which stands for \u201cprint working directory\u201d myuser@my-machine:~$ pwd /home/myuser To see a list of files and directories that exist in your current working directory, run the ls command: myuser@my-machine:~$ ls Desktop Documents Downloads Pictures Public Wallpapers You can get more details if you run ls -al command: myuser@my-machine:~$ ls -al drwxr-xr-x 2 myuser myuser 4096 Apr 30 2021 Desktop drwxrwxr-x 8 myuser myuser 4096 Oct 29 09:27 Documents drwxrwxr-x 8 myuser myuser 4096 Dec 10 14:41 Downloads drwxrwxr-x 8 myuser myuser 4096 May 23 10:43 Pictures drwxrwxr-x 8 myuser myuser 4096 Jan 19 2017 Public drwxrwxr-x 8 myuser myuser 4096 Oct 15 09:43 Wallpapers You can create one or more new directories within your current working directory with the mkdir command, which stands for \u201cmake directory\u201d. For example, to create two new directories named testdir1 and testdir2, you might run the first command. You can create nested directories by using the -p option: myuser@my-machine:~$ mkdir testdir1 testdir2 myuser@my-machine:~$ mkdir -p testdir3/testsubdir To navigate into one of these new directories, run the cd command (which stands for \u201cchange directory\u201d) and specify the directory\u2019s name: myuser@my-machine:~$ cd testdir1 myuser@my-machine:~/testdir1$ Note that you can navigate from anywhere to anywhere. cd only requires a valid filepath. Note also that . represents the current folder and .. represents the parent folder. Note also how is shows the current working directory in the shell as well. cd # This will bring you back to home directory cd testdir3/testsubdir # Brings you into testsubdir cd ../ # Brings you back out one level into testdir3 cd ../testdir1 # Brings you back out one level and back into testdir1 cd /home/<username>/testdir2 # Absolute reference to testdir2 cd ~/testdir2 # Absolute reference using tilde to testdir2","title":"Navigating the file system"},{"location":"tutorials/intro_to_linux/#working-with-files","text":"You cannot use cd to interact with files; cd stands for \u201cchange directory\u201d, and only allows you to navigate directories. You can, however, create, edit, and view the contents of files. One way to create a file is with the touch command. This creates an empty file in your current working directory. To create a new file called file.txt: touch file.txt If you decide to rename file.txt later on, you can do so with the mv command. mv stands for \u201cmove\u201d and it can move a file or directory from one place to another. By specifying the original file, file.txt, you can \u201cmove\u201d it to a new location in the current working directory, thereby renaming it. mv file.txt newfile.txt It is also possible to copy a file to a new location with the cp command. If we want to copy newfile.txt, you can make a copy of newfile.txt named newfile_copy.txt like this: cp newfile.txt newfile_copy.txt However, files are not of much use if they don\u2019t contain anything. To edit files, a file editor is necessary. There are many options for file editors, all created by professionals for daily use. Such editors include vim, emacs, nano, and pico. nano is a suitable option for beginners: it is relatively user-friendly and doesn\u2019t overload you with cryptic options or commands. nano file.txt This will open a space where you can start typing to edit the file. In nano specifically you can save your written text by pressing Ctrl + X , Y , and then Enter . This returns you to the shell with a newly saved file.txt . Now that file.txt has some text within it, you can view it using cat or less . The cat command prints the contents of a specified file to your system\u2019s output. Try running cat and pass the file.txt file you just edited as an argument: cat file.txt Using cat to view file contents can be unwieldy and difficult to read if the file is particularly long. As an alternative, you can use the less command which will allow you to paginate the output. Use less to view the contents of the file.txt file, like this: less file.txt This will also print the contents of file.txt, but one terminal page at a time beginning at the start of the file. You can use the spacebar to advance a page, or the arrow keys to go up and down one line at a time. Press Q to quit out of less . Finally, to delete the file.txt file, pass the name of the file as an argument to rm : rm file.txt rm -d directory rmidr directory rm -r directory # If the directory you are deleting is not empty NOTE : If your question has to do with a specific Linux command, the manual pages offer detailed and insightful documentation for nearly every command. To see the man page for any command, pass the command\u2019s name as an argument to the man command - man command . For instance, man rm displays the purpose of rm , how to use it, what options are available, examples of use, and more useful information. NOTE : If a command fails or is hanging or you just want to stop it, most of the time you can stop the running process by pressing Ctrl + C . This will send a Keyboard Interrupt message to the program and hopefully stop it.","title":"Working with files"},{"location":"tutorials/intro_to_linux/#connecting-the-laptop-to-the-internet-eduroam","text":"For University of Bristol students connecting to Eduroam see theese instructions","title":"Connecting the laptop to the Internet (Eduroam)"},{"location":"tutorials/intro_to_linux/#installing-dependencies-and-useful-programs","text":"Like windows and mac, individual programs can be manually downloaded (usually as a tar.gz file instead of exe ) and manually installed into your operating system (using dpkg ). However, the linux project offers a much more straight forward method through the apt (Advanced Packaging Tool) utility. apt is a free-software user interface that works with core libraries to handle the installation and removal of software on Debian operating systems like Ubuntu. (For other distributions you may come across equivalents like yum ). This is the primary method for installing software onto your system. To use apt , and more specifically apt-get which 'gets' programs for you, you must first run the update command to get the current list of all available software. Note that because sudo is used, you will most likely need to input your password. sudo will be explained below. sudo apt-get update Note that it will hang (stop responding) or fail if you are not connected to the internet.","title":"Installing Dependencies and Useful Programs"},{"location":"tutorials/intro_to_linux/#installing-git-and-vscode","text":"You can then install your programs using apt-get install . For Starling, you will need to use the git version control software to both download Starling and eventually build your own controllers. To install git , run the following: sudo apt-get install git We also recommend the use of Visual Studio Code as your development environment or text editor, but you are free to use whatever you want (atom, notepad++ etc etc). We heavily make use of it during development and recommend a number of extensions. VScode can be installed using the snap utility. snap is a slightly more modern successor to apt for more general programs. snap comes ready installed on your linux distrubtion. sudo snap install code --classic","title":"Installing Git and VSCode"},{"location":"tutorials/intro_to_linux/#sudo","text":"Now in these commands, we have prefixed all of them with sudo . sudo these days usually stands for superuser do and allows a command to be run with the privileges of the superuser (aka the root user), if the user has been given permissions to do so. Any command which installs or modifies directories outside of the users home directory will often need superuser privileges to avoid non-superusers from changing things they shouldn't. As the above commands all seek to install programs to the system, they need superuser permissions to do so. Running without sudo will give you a permission error. Running a command with sudo will ask you for your own accounts password.","title":"sudo"},{"location":"tutorials/intro_to_linux/#installing-docker","text":"For Linux systems, see the following install page . There are multiple ways of installation docker, but we recommend installing using the repository method: Update the apt repository and install requirements sudo apt-get update sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg \\ lsb-release Add Docker's official GPG key: curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg Add Docker's repository: echo \\ \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null Install Docker (and docker-compose!): sudo apt-get update sudo apt-get install docker-ce docker-ce-cli docker-compose containerd.io Test Docker installation: sudo docker run hello-world This will install Docker, accessible using sudo root privileges only. To use docker without sudo, run the following (there are security issues with this, but it doesn't matter for running Starling locally) Run the following sudo groupadd docker sudo usermod -aG docker $USER Log out and log in again to enforce changes Verify that it was successful (we will come back to this command): docker run hello-world That is Docker on Linux installed. See the original page for any further details.","title":"Installing Docker"},{"location":"tutorials/intro_to_ros/","text":"ROS2 and UAV Control \u00b6 This tutorial gives a brief overview and background on UAV Control and ROS2. By the end you should have a brief understanding of how a UAV is controlled, how Starling treats a UAV and why and how we use ROS2 to communicate with a UAV. ROS2 and UAV Control A Brief Introduction to UAV Control What is a UAV or a Drone How do you control a UAV The Autopilot MAVLink and Autopilot communication A Brief Introduction to ROS Why does ROS exist? What is ROS ROS concepts through an example ROS2 for Starling MAVLINK and ROS with MAVROS Next Steps A Brief Introduction to UAV Control \u00b6 What is a UAV or a Drone \u00b6 A drone or unmanned aerial vehicle (UAV) is an unmanned \"robotic\" vehicle that can be remotely or autonomously controlled. Drones are used for many consumer, industrial, government and military applications (opens new window). These include (non exhaustively): aerial photography/video, carrying cargo, racing, search and surveying etc. Different types of drones exist for use in air, ground, sea, and underwater. These are (more formally) referred to as Unmanned Aerial Vehicles (UAV), Unmanned Aerial Systems (UAS), Unmanned Ground Vehicles (UGV), Unmanned Surface Vehicles (USV), Unmanned Underwater Vehicles (UUV). The \"brain\" of the drone is called an autopilot . It consists of flight stack software running on vehicle controller (\"flight controller\") hardware. A multi-rotor is a specific type of UAV which uses two of more lift-generating rotors to fly. One of the most common will be the Quadrotor which has 4 motors in an 'X' pattern. These UAVs provide much simpler flight control than other types of aerial vehicle. This tutorial focuses on the flight of a simple quadrotor, but Starling can be used to operate many different types of robot. From this point on in this tutorial, 'drone' or 'UAV' will refer to a multi-rotor UAV unless otherwise stated. How do you control a UAV \u00b6 Modified from ardupilot docs A multicopter is a mechanically simple aerial vehicle whose motion is controlled by speeding or slowing multiple downward thrusting motor/propeller units. Combining different thrusts on different rotors allows the vehicle to move in free space with 6 degrees of freedom. However, manually controlling the individual thrusts of each motor in order to move the UAV is incredibly difficult, most would say its impossible even. This instability means that an on-board computer is mandatory for stable flight, as the on-board controller can perform the extreme high-rate control required to keep the drone in the air. In this \"Fly by wire\" paradigm, if the computer isn't working, you aren't flying. This dedicated on-board controller is referred to as the autopilot . This is seperate from a companion computer which is often used to direct the autopilot to achieve higher level mission goals. The autopilot combines data from small on-board MEMs gyroscopes and accelerometers (the same as those found in smart phones) to maintain an accurate estimate of its orientation and position. The quadcopter shown above is the simplest type of multicopter, with each motor/propeller spinning in the opposite direction from the two motors on either side of it (i.e. motors on opposite corners of the frame spin in the same direction). A quadcopter can control its roll and pitch rotation by speeding up two motors on one side and slowing down the other two. So for example if the quadcopter wanted to roll left it would speed up motors on the right side of the frame and slow down the two on the left. Similarly if it wants to rotate forward it speeds up the back two motors and slows down the front two. The copter can turn (aka \u201cyaw\u201d) left or right by speeding up two motors that are diagonally across from each other, and slowing down the other two. Horizontal motion is accomplished by temporarily speeding up/slowing down some motors so that the vehicle is leaning in the direction of desired travel and increasing the overall thrust of all motors so the vehicle shoots forward. Generally the more the vehicle leans, the faster it travels. Altitude is controlled by speeding up or slowing down all motors at the same time. In order to automatically map higher level motions to the thrust of the rotors, a cascading set of PID controllers is designed and provided by the autopilot. These then allow the remote control flight of the vehicle from a transmitter in your pilots hands, or via messages sent by the companion computer The Autopilot \u00b6 There is no universal controller design of converting from user inputs to motor thrust. In the same way, there are numerous other functionalities that an autopilot can cover. These can range from running control loops for gimbals, cameras and other actuation, to high level mission following and safety features. These functionalities are bundled into specific autopilot firmwares which each offer a slightly different set of features, as well as differing user interfaces each with their advantages and drawbacks. The two current most common autopilot firmware's in use in research settings are Ardupilot which offers the Arducopter firmware, and PX4 which offers Multicopter firmware. Both these firmwares are very extensive and cover numerous use cases. However, for our purposes we will only cover enabling autonomous flight through observing the mode of the autpilot. Both Ardupilot and PX4 use the concept of flight modes, where each mode operates a supports different levels or types of flight stabilisation and/or autonomous functions. Traditionally this is for pilots to change between different controller layouts for different applications. It's necessary to change to the correct mode for safe and controllable flight. The following table shows the most often used flight modes within Starling. Ardupilot Mode PX4 Mode Functionality stabilized manual Full manual control with RC sticks being sent directly to control roll, pitch, yaw and height PosHold position UAV uses onboard sensing to stay in place, RC sticks used to translate position loiter auto.hold Automatic mode where UAV stays in the same location until further instructions given. land auto.land Automatic mode which attempts to land the UAV Guided offboard Navigates to setpoints sent to it by ground control or companion computer Our controllers will all ask the autopilot to switch into guided or offboard mode in order to control from the companion computer. Often they have safety elements build in which mean that the autopilot must receive instructions at a certain rate (2Hz) otherwise the autopilot will switch to loiter or land. As mentioned before, the firmware provides a given cascading PID controller for converting high level commands to motor thrusts. As a controller developer, it is also useful to understand the differences between the Ardupilot and PX4 controllers and what real world impacts that has. Thankfully in most of Starling's targeted applications we only require position control which works fairly consistently between the two firmwares. In our own work, it has generally been noted that Ardupilot seems to be more suitable for outdoor flight, and PX4 for indoor flight. For this tutorial we will be developing a controller for indoor multi-vehicle flight and so we will assume the use of PX4. If interested in outdoor flight with Ardupilot, check out this tutorial which uses Starling with Ardupilot to simulate outdoor drone flight over a volcano. MAVLink and Autopilot communication \u00b6 Once in guided or offboard mode, the autopilot expects communications using the MAVLINK protocol . Traditionally this would have been used for a ground control station (GCS) to send commands to a UAV over a telemetry link. However, now it has also developed into a protocol for commanding the autopilot from an onboard companion computer over a USB or serial connection too. In Starling, both methods of communication between GCS or companion computer are supported. The MAVLink protocol is a set of preset commands which compatible firmwares understand and react to. However, it is often verbose and not-intuitive to develop applications with, as well as requiring a lot of prior knowledge about the state of the system. For example, it is neccesary to send a number of specific messages in order to receive individual data streams on vehicle status, location, global location and so on. These are often missed and cause lots of headaches for developers. Starling aims to streamline this through the use of the Robot Operating System so users no longer need to interact with MAVLink and the autopilot directly. A Brief Introduction to ROS \u00b6 This sections is adapted from this article ROS stands for the Robot Operating System, yet it isn't an actual operating system. It's a framework designed to expedite the development time of robot platforms. To understand what ROS is, we should understand why ROS exists in the first place. Why does ROS exist? \u00b6 In general, software developers avoid hardware like the plague. It's messy, doesn't have consistent behavior, and there's no ctrl-z in sight. Most beginner programmers think you have to have a deep knowledge of electronics and even mechanics to program robots. They think that the hardware and software are so tightly coupled, you have to know both in depth to build anything useful. Software developers became software developers for a reason, so they don't have to deal with hardware. For example, lets say you have to debug a faulty sensor. You first have to take out the sensor from the enclosure, test the sensor thoroughly with a multi meter and various test cases, document its behavior, then examine the hardware -level code to ensure that there were no bugs, and so on. That's a lot of interaction with the hardware that's not fun for someone who just wants to write some cool software. It's harder to attract good programmers if the programming is coupled deeply with hardware. This is where ROS comes into play. With ROS, you can completely abstract the hardware from software, and instead interact with an API that gives access to that data. You can forget about the hardware, and focus on developing the software that makes the robot do what you want. What is ROS \u00b6 ROS is essentially a framework that sits on top of an operating system which defines how particular ROS compatible programs communicate and share data with each other. Essentially ROS defines an interface between which compatible programs can communicate and interact with each other. Over the years that ROS has existed, many people have developed thousands of ROS compatible packages which can be used in a modular fashion. ROS concepts through an example \u00b6 To make it more concrete, imagine that on your drone you have a camera. There are also two processes which require, as inputs, that camera image. Say, a machine learning program, and a position estimation program. Traditionally, you would have to manually serialise (compress) and stream the image over a port which the other two programs could read from. But if the port changes or, say, the camera changes, lots of things have to be reconfigured. However, this sort of interaction can be made streamlined in ROS. Let us consider the programs we have as ROS nodes , i.e. a program which is responsible for one single modular purpose, with particular inputs or outputs: A camera image streaming node OUT: camera image A machine vision system for recognising objects IN: camera image OUT: list of recognised objects A simultaneous localisation and mapping system. IN: camera image OUT: vehicle position These outputs of a node define ROS topics , i.e. a single stream of one type of data. Each topic has a particular name which can be referred to. In our example, some of the topics might be: /drone/camera for the camera image /drone/recognised_objects for the machine vision system /drone/slam_position for the SLAM system Then, we see that there are two avenues of communication created from these node inputs and outputs. graph LR A[Camera] -->|out| node[drone/camera] node --in--> C[Machine Vision] node --in--> D[SLAM] style node fill:#f9f,stroke:#333,stroke-width:4px Now ROS follows a publisher/subscriber model of communication. What that means is that nodes publish data to topics as outputs. But that data is only sent across the network if a different nodes also subscribes to the same topic. So in our example we end up having A camera image streaming node OUT: publishing to /drone/camera A machine vision system for recognising objects IN: subscribed to /drone/camera OUT: publishing to /drone/recognised_objects A simultaneous localisation and mapping system. IN: subscribed to /drone/camera OUT: publishing to /drone/slam_position graph LR A[Camera] -->|out| node[drone/camera] node --in--> C[Vision] C -->|out| node1[drone/recognised_objects] node --in--> D[SLAM] D -->|out| node2[drone/slam_position] style node fill:#f9f,stroke:#333,stroke-width:4px style node1 fill:#f9f,stroke:#333,stroke-width:4px style node2 fill:#f9f,stroke:#333,stroke-width:4px Finally, the data that is sent is not just anything. The data or message is a specifically templated packet of data containing things specified for that paricular use case. In our example for /drone/slam_position topic, the message might be of type geometry_msgs/msg/Point.msg which is defined like so: # This contains the position of a point in free space float64 x float64 y float64 z In other words the message that the /drone/slam_position topic publishes must have a msg.x , msg.y and msg.z field, and the subscriber will only receivea message with those fields. There are a number of messages in the standard ROS library, but many libraries also define their own - as have we in some parts of Starling. This can be summarised in this diagram from the ROS tutorials demonstrates it very nicely: The bottom half of this shows how topics get sent from a publisher to a subscriber. Interestingly, if you put two topics together, you get some notion of two way communication. This is the basis of a service which can be seen in the top of the diagram. A service is made of a Request topic and a Response topic, but functions as a single communication type to the user. Similar to messages, a service has a defined request and response types (e.g. see std_srvs/srv/SetBool.srv ). A service request will often wait until a response is received before continuing. Note that everything happens asyncronously and in parallel, when a node subscribes or sends a requests, it doesn't know when the response will arrive. It only knows it will (hopefully) arrive at some point. When a packet is received the subscriber can then run a method - this method is usually known as a callback , but that will be covered in a later tutorial. So in summary, the key conepts and terminology are: Nodes Topics Publishers and Subscribers Messages Services ROS2 for Starling \u00b6 There are 2 versions of ROS - ROS1 and ROS2. ROS1, initially created in 2007 by Willow Garage, has become huge among the open source robotics community. However over the years they realised that there are a number of important features which are missing - and adding all of these would simply break ROS1. Also the most recent ROS1 distribution (ROS Noetic) is soon to reach the end of its supported life (EOL 2025) with no more ROS1 there after! (See this article for more details!) Therefore, to future proof the system, and to ensure all users get a well rounded experience that will hopefully translate to industry experience, Starling has been implemented in ROS2. Specifically, Starling uses the Foxy Fitzroy Long Term Support (LTS) distribution throughout. There are some interesting changes between ROS1 and ROS2, but the core elements described above remain identical. A future tutorial will go into a few more details, but this is probably all the context you will need for now! Note: Main thing to be aware of is if you are debugging and searching for ROS questions on the internet, be aware that there are many existing questions for ROS1 which will no longer apply for ROS2. MAVLINK and ROS with MAVROS \u00b6 Coming back round to flying drones, we mentioned in that we wanted to use ROS to avoid having to manually communicate with the autopilot using MAVLINK. Starling uses the MAVROS ROS package to do exactly that. For the autpilot, it automatically sets up a connection and translates higher level ROS commands into MAVLINK commands. For controller developers, Mavros provides a known and consistent interface through a set of topics, services and parameters to interact with. These include high level actions such as requesting the vehicle's state, local position, gps position, as well as setting setpoints for the vehicle to visit. A couple of useful topics are in the following table: Name Topic Message Type Functionality State mavros/state mavros_msgs/msg/State Get's the current state and flight mode of the vehicle Local Position mavros/local_position/pose geometry_msgs/msg/PoseStamped Get the UAVs current coordinate position after sensor fusion GPS Position mavros/global_position/global sensor_msgs/msg/NavSatFix Get the UAVs current lat,long (if enabled) Position Setpoint mavros/setpoint_position/local geometry_msgs/msg/PoseStamped Send a target coordinate and orientation for the vehicle to fly to immediately Set Flight Mode mavros/set_mode mavros_msgs/srv/SetMode A service which sets the flight mode of the autopilot Set Data Stream Rate mavros/set_stream_rate mavros_msgs/srv/StreamRate A service which starts the data stream from the autopilot and sets its rate Sometimes, you may need to send raw MAVlink back to the Autopilot to enable some non-standard functionality. This can also be done through the MAVROS node too. As we are now utilising ROS, this allows us to make the most of the full ROS ecosystem in developing UAV applications. Next Steps \u00b6 Hopefully now you have a basic understanding of what a drone is and how they are controlled, the function and purpose of an autopilot, as well as how ROS functions can be used. If you want some early hands on experience with ROS before delving further into Starling, we highly recommend the offical ros2 tutorials . We have one more theory topic before you can start creating your own Starling projects, where we will be discussing how Starling uses and encapsulates ROS functionality.","title":"4. A Brief Introduction to ROS"},{"location":"tutorials/intro_to_ros/#ros2-and-uav-control","text":"This tutorial gives a brief overview and background on UAV Control and ROS2. By the end you should have a brief understanding of how a UAV is controlled, how Starling treats a UAV and why and how we use ROS2 to communicate with a UAV. ROS2 and UAV Control A Brief Introduction to UAV Control What is a UAV or a Drone How do you control a UAV The Autopilot MAVLink and Autopilot communication A Brief Introduction to ROS Why does ROS exist? What is ROS ROS concepts through an example ROS2 for Starling MAVLINK and ROS with MAVROS Next Steps","title":"ROS2 and UAV Control"},{"location":"tutorials/intro_to_ros/#a-brief-introduction-to-uav-control","text":"","title":"A Brief Introduction to UAV Control"},{"location":"tutorials/intro_to_ros/#what-is-a-uav-or-a-drone","text":"A drone or unmanned aerial vehicle (UAV) is an unmanned \"robotic\" vehicle that can be remotely or autonomously controlled. Drones are used for many consumer, industrial, government and military applications (opens new window). These include (non exhaustively): aerial photography/video, carrying cargo, racing, search and surveying etc. Different types of drones exist for use in air, ground, sea, and underwater. These are (more formally) referred to as Unmanned Aerial Vehicles (UAV), Unmanned Aerial Systems (UAS), Unmanned Ground Vehicles (UGV), Unmanned Surface Vehicles (USV), Unmanned Underwater Vehicles (UUV). The \"brain\" of the drone is called an autopilot . It consists of flight stack software running on vehicle controller (\"flight controller\") hardware. A multi-rotor is a specific type of UAV which uses two of more lift-generating rotors to fly. One of the most common will be the Quadrotor which has 4 motors in an 'X' pattern. These UAVs provide much simpler flight control than other types of aerial vehicle. This tutorial focuses on the flight of a simple quadrotor, but Starling can be used to operate many different types of robot. From this point on in this tutorial, 'drone' or 'UAV' will refer to a multi-rotor UAV unless otherwise stated.","title":"What is a UAV or a Drone"},{"location":"tutorials/intro_to_ros/#how-do-you-control-a-uav","text":"Modified from ardupilot docs A multicopter is a mechanically simple aerial vehicle whose motion is controlled by speeding or slowing multiple downward thrusting motor/propeller units. Combining different thrusts on different rotors allows the vehicle to move in free space with 6 degrees of freedom. However, manually controlling the individual thrusts of each motor in order to move the UAV is incredibly difficult, most would say its impossible even. This instability means that an on-board computer is mandatory for stable flight, as the on-board controller can perform the extreme high-rate control required to keep the drone in the air. In this \"Fly by wire\" paradigm, if the computer isn't working, you aren't flying. This dedicated on-board controller is referred to as the autopilot . This is seperate from a companion computer which is often used to direct the autopilot to achieve higher level mission goals. The autopilot combines data from small on-board MEMs gyroscopes and accelerometers (the same as those found in smart phones) to maintain an accurate estimate of its orientation and position. The quadcopter shown above is the simplest type of multicopter, with each motor/propeller spinning in the opposite direction from the two motors on either side of it (i.e. motors on opposite corners of the frame spin in the same direction). A quadcopter can control its roll and pitch rotation by speeding up two motors on one side and slowing down the other two. So for example if the quadcopter wanted to roll left it would speed up motors on the right side of the frame and slow down the two on the left. Similarly if it wants to rotate forward it speeds up the back two motors and slows down the front two. The copter can turn (aka \u201cyaw\u201d) left or right by speeding up two motors that are diagonally across from each other, and slowing down the other two. Horizontal motion is accomplished by temporarily speeding up/slowing down some motors so that the vehicle is leaning in the direction of desired travel and increasing the overall thrust of all motors so the vehicle shoots forward. Generally the more the vehicle leans, the faster it travels. Altitude is controlled by speeding up or slowing down all motors at the same time. In order to automatically map higher level motions to the thrust of the rotors, a cascading set of PID controllers is designed and provided by the autopilot. These then allow the remote control flight of the vehicle from a transmitter in your pilots hands, or via messages sent by the companion computer","title":"How do you control a UAV"},{"location":"tutorials/intro_to_ros/#the-autopilot","text":"There is no universal controller design of converting from user inputs to motor thrust. In the same way, there are numerous other functionalities that an autopilot can cover. These can range from running control loops for gimbals, cameras and other actuation, to high level mission following and safety features. These functionalities are bundled into specific autopilot firmwares which each offer a slightly different set of features, as well as differing user interfaces each with their advantages and drawbacks. The two current most common autopilot firmware's in use in research settings are Ardupilot which offers the Arducopter firmware, and PX4 which offers Multicopter firmware. Both these firmwares are very extensive and cover numerous use cases. However, for our purposes we will only cover enabling autonomous flight through observing the mode of the autpilot. Both Ardupilot and PX4 use the concept of flight modes, where each mode operates a supports different levels or types of flight stabilisation and/or autonomous functions. Traditionally this is for pilots to change between different controller layouts for different applications. It's necessary to change to the correct mode for safe and controllable flight. The following table shows the most often used flight modes within Starling. Ardupilot Mode PX4 Mode Functionality stabilized manual Full manual control with RC sticks being sent directly to control roll, pitch, yaw and height PosHold position UAV uses onboard sensing to stay in place, RC sticks used to translate position loiter auto.hold Automatic mode where UAV stays in the same location until further instructions given. land auto.land Automatic mode which attempts to land the UAV Guided offboard Navigates to setpoints sent to it by ground control or companion computer Our controllers will all ask the autopilot to switch into guided or offboard mode in order to control from the companion computer. Often they have safety elements build in which mean that the autopilot must receive instructions at a certain rate (2Hz) otherwise the autopilot will switch to loiter or land. As mentioned before, the firmware provides a given cascading PID controller for converting high level commands to motor thrusts. As a controller developer, it is also useful to understand the differences between the Ardupilot and PX4 controllers and what real world impacts that has. Thankfully in most of Starling's targeted applications we only require position control which works fairly consistently between the two firmwares. In our own work, it has generally been noted that Ardupilot seems to be more suitable for outdoor flight, and PX4 for indoor flight. For this tutorial we will be developing a controller for indoor multi-vehicle flight and so we will assume the use of PX4. If interested in outdoor flight with Ardupilot, check out this tutorial which uses Starling with Ardupilot to simulate outdoor drone flight over a volcano.","title":"The Autopilot"},{"location":"tutorials/intro_to_ros/#mavlink-and-autopilot-communication","text":"Once in guided or offboard mode, the autopilot expects communications using the MAVLINK protocol . Traditionally this would have been used for a ground control station (GCS) to send commands to a UAV over a telemetry link. However, now it has also developed into a protocol for commanding the autopilot from an onboard companion computer over a USB or serial connection too. In Starling, both methods of communication between GCS or companion computer are supported. The MAVLink protocol is a set of preset commands which compatible firmwares understand and react to. However, it is often verbose and not-intuitive to develop applications with, as well as requiring a lot of prior knowledge about the state of the system. For example, it is neccesary to send a number of specific messages in order to receive individual data streams on vehicle status, location, global location and so on. These are often missed and cause lots of headaches for developers. Starling aims to streamline this through the use of the Robot Operating System so users no longer need to interact with MAVLink and the autopilot directly.","title":"MAVLink and Autopilot communication"},{"location":"tutorials/intro_to_ros/#a-brief-introduction-to-ros","text":"This sections is adapted from this article ROS stands for the Robot Operating System, yet it isn't an actual operating system. It's a framework designed to expedite the development time of robot platforms. To understand what ROS is, we should understand why ROS exists in the first place.","title":"A Brief Introduction to ROS"},{"location":"tutorials/intro_to_ros/#why-does-ros-exist","text":"In general, software developers avoid hardware like the plague. It's messy, doesn't have consistent behavior, and there's no ctrl-z in sight. Most beginner programmers think you have to have a deep knowledge of electronics and even mechanics to program robots. They think that the hardware and software are so tightly coupled, you have to know both in depth to build anything useful. Software developers became software developers for a reason, so they don't have to deal with hardware. For example, lets say you have to debug a faulty sensor. You first have to take out the sensor from the enclosure, test the sensor thoroughly with a multi meter and various test cases, document its behavior, then examine the hardware -level code to ensure that there were no bugs, and so on. That's a lot of interaction with the hardware that's not fun for someone who just wants to write some cool software. It's harder to attract good programmers if the programming is coupled deeply with hardware. This is where ROS comes into play. With ROS, you can completely abstract the hardware from software, and instead interact with an API that gives access to that data. You can forget about the hardware, and focus on developing the software that makes the robot do what you want.","title":"Why does ROS exist?"},{"location":"tutorials/intro_to_ros/#what-is-ros","text":"ROS is essentially a framework that sits on top of an operating system which defines how particular ROS compatible programs communicate and share data with each other. Essentially ROS defines an interface between which compatible programs can communicate and interact with each other. Over the years that ROS has existed, many people have developed thousands of ROS compatible packages which can be used in a modular fashion.","title":"What is ROS"},{"location":"tutorials/intro_to_ros/#ros-concepts-through-an-example","text":"To make it more concrete, imagine that on your drone you have a camera. There are also two processes which require, as inputs, that camera image. Say, a machine learning program, and a position estimation program. Traditionally, you would have to manually serialise (compress) and stream the image over a port which the other two programs could read from. But if the port changes or, say, the camera changes, lots of things have to be reconfigured. However, this sort of interaction can be made streamlined in ROS. Let us consider the programs we have as ROS nodes , i.e. a program which is responsible for one single modular purpose, with particular inputs or outputs: A camera image streaming node OUT: camera image A machine vision system for recognising objects IN: camera image OUT: list of recognised objects A simultaneous localisation and mapping system. IN: camera image OUT: vehicle position These outputs of a node define ROS topics , i.e. a single stream of one type of data. Each topic has a particular name which can be referred to. In our example, some of the topics might be: /drone/camera for the camera image /drone/recognised_objects for the machine vision system /drone/slam_position for the SLAM system Then, we see that there are two avenues of communication created from these node inputs and outputs. graph LR A[Camera] -->|out| node[drone/camera] node --in--> C[Machine Vision] node --in--> D[SLAM] style node fill:#f9f,stroke:#333,stroke-width:4px Now ROS follows a publisher/subscriber model of communication. What that means is that nodes publish data to topics as outputs. But that data is only sent across the network if a different nodes also subscribes to the same topic. So in our example we end up having A camera image streaming node OUT: publishing to /drone/camera A machine vision system for recognising objects IN: subscribed to /drone/camera OUT: publishing to /drone/recognised_objects A simultaneous localisation and mapping system. IN: subscribed to /drone/camera OUT: publishing to /drone/slam_position graph LR A[Camera] -->|out| node[drone/camera] node --in--> C[Vision] C -->|out| node1[drone/recognised_objects] node --in--> D[SLAM] D -->|out| node2[drone/slam_position] style node fill:#f9f,stroke:#333,stroke-width:4px style node1 fill:#f9f,stroke:#333,stroke-width:4px style node2 fill:#f9f,stroke:#333,stroke-width:4px Finally, the data that is sent is not just anything. The data or message is a specifically templated packet of data containing things specified for that paricular use case. In our example for /drone/slam_position topic, the message might be of type geometry_msgs/msg/Point.msg which is defined like so: # This contains the position of a point in free space float64 x float64 y float64 z In other words the message that the /drone/slam_position topic publishes must have a msg.x , msg.y and msg.z field, and the subscriber will only receivea message with those fields. There are a number of messages in the standard ROS library, but many libraries also define their own - as have we in some parts of Starling. This can be summarised in this diagram from the ROS tutorials demonstrates it very nicely: The bottom half of this shows how topics get sent from a publisher to a subscriber. Interestingly, if you put two topics together, you get some notion of two way communication. This is the basis of a service which can be seen in the top of the diagram. A service is made of a Request topic and a Response topic, but functions as a single communication type to the user. Similar to messages, a service has a defined request and response types (e.g. see std_srvs/srv/SetBool.srv ). A service request will often wait until a response is received before continuing. Note that everything happens asyncronously and in parallel, when a node subscribes or sends a requests, it doesn't know when the response will arrive. It only knows it will (hopefully) arrive at some point. When a packet is received the subscriber can then run a method - this method is usually known as a callback , but that will be covered in a later tutorial. So in summary, the key conepts and terminology are: Nodes Topics Publishers and Subscribers Messages Services","title":"ROS concepts through an example"},{"location":"tutorials/intro_to_ros/#ros2-for-starling","text":"There are 2 versions of ROS - ROS1 and ROS2. ROS1, initially created in 2007 by Willow Garage, has become huge among the open source robotics community. However over the years they realised that there are a number of important features which are missing - and adding all of these would simply break ROS1. Also the most recent ROS1 distribution (ROS Noetic) is soon to reach the end of its supported life (EOL 2025) with no more ROS1 there after! (See this article for more details!) Therefore, to future proof the system, and to ensure all users get a well rounded experience that will hopefully translate to industry experience, Starling has been implemented in ROS2. Specifically, Starling uses the Foxy Fitzroy Long Term Support (LTS) distribution throughout. There are some interesting changes between ROS1 and ROS2, but the core elements described above remain identical. A future tutorial will go into a few more details, but this is probably all the context you will need for now! Note: Main thing to be aware of is if you are debugging and searching for ROS questions on the internet, be aware that there are many existing questions for ROS1 which will no longer apply for ROS2.","title":"ROS2 for Starling"},{"location":"tutorials/intro_to_ros/#mavlink-and-ros-with-mavros","text":"Coming back round to flying drones, we mentioned in that we wanted to use ROS to avoid having to manually communicate with the autopilot using MAVLINK. Starling uses the MAVROS ROS package to do exactly that. For the autpilot, it automatically sets up a connection and translates higher level ROS commands into MAVLINK commands. For controller developers, Mavros provides a known and consistent interface through a set of topics, services and parameters to interact with. These include high level actions such as requesting the vehicle's state, local position, gps position, as well as setting setpoints for the vehicle to visit. A couple of useful topics are in the following table: Name Topic Message Type Functionality State mavros/state mavros_msgs/msg/State Get's the current state and flight mode of the vehicle Local Position mavros/local_position/pose geometry_msgs/msg/PoseStamped Get the UAVs current coordinate position after sensor fusion GPS Position mavros/global_position/global sensor_msgs/msg/NavSatFix Get the UAVs current lat,long (if enabled) Position Setpoint mavros/setpoint_position/local geometry_msgs/msg/PoseStamped Send a target coordinate and orientation for the vehicle to fly to immediately Set Flight Mode mavros/set_mode mavros_msgs/srv/SetMode A service which sets the flight mode of the autopilot Set Data Stream Rate mavros/set_stream_rate mavros_msgs/srv/StreamRate A service which starts the data stream from the autopilot and sets its rate Sometimes, you may need to send raw MAVlink back to the Autopilot to enable some non-standard functionality. This can also be done through the MAVROS node too. As we are now utilising ROS, this allows us to make the most of the full ROS ecosystem in developing UAV applications.","title":"MAVLINK and ROS with MAVROS"},{"location":"tutorials/intro_to_ros/#next-steps","text":"Hopefully now you have a basic understanding of what a drone is and how they are controlled, the function and purpose of an autopilot, as well as how ROS functions can be used. If you want some early hands on experience with ROS before delving further into Starling, we highly recommend the offical ros2 tutorials . We have one more theory topic before you can start creating your own Starling projects, where we will be discussing how Starling uses and encapsulates ROS functionality.","title":"Next Steps"},{"location":"tutorials/running/","text":"Running the Example Fenswood Scenario \u00b6 This year, the group project revolves around the flight of a single UAV to a 'volcano' at Fenswood Farm. Therefore we have provided this fenswood scenario to all students. The fenswood scenario repository is here: https://github.com/StarlingUAS/FenswoodScenario This section takes you through step by step as to how to download and run the example, and a bit of information as to what the example contains. This information is also in the example repository README. Getting the Example Scenario \u00b6 The example is packaged as github repository. For information on what is github see this article . In order to run the example scenario, you will first need to 'clone' the repository locally. Therefore, navigate to a location in the file system where you want to store the repository (e.g. cd ~/Documents ) and run the following: git clone https://github.com/StarlingUAS/FenswoodScenario.git Note : this is why we needed to install git earlier using apt This will download the repository folder into your local directory. Navigate into the folder using cd : myuser@my-machine:~/Documents$ cd FenswoodScenario myuser@my-machine:~/Documents/FenswoodScenario$ ls Dockerfile README.md docker-compose.example_drone_controller.yaml docs fenswood mkdocs.yml Makefile docker-bake.hcl docker-compose.yml example_controller_python_ap foxglove_layout.json simulation Then you will need to download the associated starling containers to run the simulator and SITL. Thankfully, this is fairly straightforward and can be run by doing the following: myuser@my-machine:~/Documents/FenswoodScenario$ docker-compose -f docker-compose.yml pull Pulling simhost ... done Pulling sitl ... Pulling mavros ... Pulling rosbridge-suite ... Pulling ui Breaking down this command, docker-compose is a utility which allows us to compose together multiple docker containers, i.e. run multiple containers together. -f docker-compose.yml specifies that docker-compose should read the configuration yaml file given by -f . docker-compose.yml is a configuration file we have written which specifies the containers and configurations required to run the fenswood scenario. In this file, we have speciifed that 6 containers will be run. pull specifies that we would like to download the required containers locally, but not run them just yet. Note: if the file is called docker-compose.yml or docker-compose.yaml the -f option does not need to be specified, we are doing it here for completeness. Try it: docker-compose pull This command may take between 10 minutes as it has to download some large content - the simulator itself is around 5Gb! It is recommended you keep reading and have a look at section 5.4 (a brief introduction to ROS) while waiting. The downloaded containers are not stored in your local directory, instead they are stored by docker in a local library on your own machine. All downloaded and local containers can be seen by typing. myuser@my-machine:~/Documents/FenswoodScenario$ docker images Running the Example Scenario \u00b6 Once the download of pull has completed, you can run the scenario. To run the example scenario, it is a similar command except now you ask it to up : The simulator is build locally, so this may take a few minutes too to download dependencies and such. myuser@my-machine:~/Documents/FenswoodScenario$ docker-compose up This will start 4 containers: simhost : The physics simulator instance which also hosts the simulated drone model and the target spawning. sitl : The software in the loop representing the onboard autopilot software. mavros : This is the bridge between Mavlink and ROS. It also serves to send mavlink messages to a ground station. rosbridge-suite : This is a ros-web interface that is placed there for future use. ui : This is the example ui. Wait a minute or so for all of the containers to initialise. Once started, the simulator should be available to see in the browser. Open up the firefox browser (click on firefox on the sidebar, or press Win and search for firefox) Go to localhost:8080 You should see something like the following The web interface is known as Gazebo Web. You can fly your camera through the environment like many other 3D modelling software: Left Click on a location and drag does Panning/Translating Middle Click on a location and drag does rotating around a point Scrolling the Middle Mouse button will zoom you in and out. The full process as a gif: To stop the simulator from running, select this terminal and press Ctrl+c . Pressing once will shutdown the containers gracefully. Pressing twice will attempt to immediately kill all contianers.","title":"3. Running the Example Fenswood Scenario"},{"location":"tutorials/running/#running-the-example-fenswood-scenario","text":"This year, the group project revolves around the flight of a single UAV to a 'volcano' at Fenswood Farm. Therefore we have provided this fenswood scenario to all students. The fenswood scenario repository is here: https://github.com/StarlingUAS/FenswoodScenario This section takes you through step by step as to how to download and run the example, and a bit of information as to what the example contains. This information is also in the example repository README.","title":"Running the Example Fenswood Scenario"},{"location":"tutorials/running/#getting-the-example-scenario","text":"The example is packaged as github repository. For information on what is github see this article . In order to run the example scenario, you will first need to 'clone' the repository locally. Therefore, navigate to a location in the file system where you want to store the repository (e.g. cd ~/Documents ) and run the following: git clone https://github.com/StarlingUAS/FenswoodScenario.git Note : this is why we needed to install git earlier using apt This will download the repository folder into your local directory. Navigate into the folder using cd : myuser@my-machine:~/Documents$ cd FenswoodScenario myuser@my-machine:~/Documents/FenswoodScenario$ ls Dockerfile README.md docker-compose.example_drone_controller.yaml docs fenswood mkdocs.yml Makefile docker-bake.hcl docker-compose.yml example_controller_python_ap foxglove_layout.json simulation Then you will need to download the associated starling containers to run the simulator and SITL. Thankfully, this is fairly straightforward and can be run by doing the following: myuser@my-machine:~/Documents/FenswoodScenario$ docker-compose -f docker-compose.yml pull Pulling simhost ... done Pulling sitl ... Pulling mavros ... Pulling rosbridge-suite ... Pulling ui Breaking down this command, docker-compose is a utility which allows us to compose together multiple docker containers, i.e. run multiple containers together. -f docker-compose.yml specifies that docker-compose should read the configuration yaml file given by -f . docker-compose.yml is a configuration file we have written which specifies the containers and configurations required to run the fenswood scenario. In this file, we have speciifed that 6 containers will be run. pull specifies that we would like to download the required containers locally, but not run them just yet. Note: if the file is called docker-compose.yml or docker-compose.yaml the -f option does not need to be specified, we are doing it here for completeness. Try it: docker-compose pull This command may take between 10 minutes as it has to download some large content - the simulator itself is around 5Gb! It is recommended you keep reading and have a look at section 5.4 (a brief introduction to ROS) while waiting. The downloaded containers are not stored in your local directory, instead they are stored by docker in a local library on your own machine. All downloaded and local containers can be seen by typing. myuser@my-machine:~/Documents/FenswoodScenario$ docker images","title":"Getting the Example Scenario"},{"location":"tutorials/running/#running-the-example-scenario","text":"Once the download of pull has completed, you can run the scenario. To run the example scenario, it is a similar command except now you ask it to up : The simulator is build locally, so this may take a few minutes too to download dependencies and such. myuser@my-machine:~/Documents/FenswoodScenario$ docker-compose up This will start 4 containers: simhost : The physics simulator instance which also hosts the simulated drone model and the target spawning. sitl : The software in the loop representing the onboard autopilot software. mavros : This is the bridge between Mavlink and ROS. It also serves to send mavlink messages to a ground station. rosbridge-suite : This is a ros-web interface that is placed there for future use. ui : This is the example ui. Wait a minute or so for all of the containers to initialise. Once started, the simulator should be available to see in the browser. Open up the firefox browser (click on firefox on the sidebar, or press Win and search for firefox) Go to localhost:8080 You should see something like the following The web interface is known as Gazebo Web. You can fly your camera through the environment like many other 3D modelling software: Left Click on a location and drag does Panning/Translating Middle Click on a location and drag does rotating around a point Scrolling the Middle Mouse button will zoom you in and out. The full process as a gif: To stop the simulator from running, select this terminal and press Ctrl+c . Pressing once will shutdown the containers gracefully. Pressing twice will attempt to immediately kill all contianers.","title":"Running the Example Scenario"},{"location":"tutorials/running_controller/","text":"Running the Example UAV Controller \u00b6 The next step in getting the Fenswood Scenario up and running is to actually get the UAV to do something. The previous steps simply started the simulator up, but now we have to instruct and control the UAV. For now we have provided an example controller to all students in the same FenswoodScenario repository under example_controller_python_ap . This section will take you through step by step as to how to download and run the example, a bit of information about what the example contains. This information is also available in the example repository readme. Running the Example Controller \u00b6 First, open up a terminal and start up the Fenswood Scenario Simulator if you haven't already (Refer to ). Double check it is open by going to Gazebo Web at localhost:8080 Then, open up a second terminal and navigate to the FenswoodScenario repository folder. The example controller can be started by running the following: myuser@my-machine:~/Documents/FenswoodScenario$ docker-compose -f docker-compose.example_drone_controller.yaml up With this command, the controller will start off and attempt to find a drone on the network. If a drone has not been found, try restarting the both the Fenswood Scenario and the controller. Once a drone has been found, it will attempt to connect to the ardupilot. Once connected the path the vehicle will take is initialised and it is ready to fly if the user sends a mission go. Be patient, sometimes the ardupilot SITL can be quite slow to respond. Leave it for up to 2 or 3 minutes before trying again. Now to send a mission go, you can use the provided simple UI that is started with the FenswoodScenario. Navigate to localhost:3000 in the browser, and a UI will start up: If it says connected to rosbridge in green, then you are ready to send a mission start command. Press the Green GO Button. If you go to the terminal it should start sending waypoints. In the UI the camera image should start to change as the vehicle takes off, and you should see the vehicle takeoff in gazebo web as well. Then you should hopefully see its attempt to follow a preset trajectory towards the target location. This full process can be seen in the following gif (The commands are outdated, but you should see something very similar): The landing: What is the Example Controller \u00b6 So what exactly is the example controller doing? Lets first start with what it is communicating with. On a real drone, the thing that controls the lower level operations of the drone is the Autopilot or Flight controller . The autopilot contains software which allows for different flight modes and translates hight level commands to motor voltages to fly the drone. As you might have come across, the primary with of controlling the autopilot is through sending Mavlink messages. Now the autopilot software itself can be swapped out and changed. For this scenario, we use the Ardupilot Arducopter firmware for the flight controller. It is important to know the specific type of software as different flight controller firmware requires the use of different flight mode and instructions. The Fenswood Scenario simulator utilises the Ardupilot Software In The Loop (SITL) simulator. This program is identical to the firmware that would be running onboard the flight controller. Then, within the example controller repository, there are two example controllers - one for Ardupilot (suffixed with ap ), and one for the PX4 firmware (suffixed with px4 ). You can use the former to communicate with the Ardupilot SITL. The example controller talks in ROS2 to the SITL via the Mavros translation node mentioned earlier. It sends commands for things like 'takeoff', 'go there' and 'land' via topics which the Mavros node advertises. The Mavros node takes subscribes to these topics and re-publishes them to the Flight Controller using Mavlink in a way Ardupilot understands. More details will be given in the next tutorial about how this controller works under the hood, and how to develop your own.","title":"5. Running the Example UAV Controller"},{"location":"tutorials/running_controller/#running-the-example-uav-controller","text":"The next step in getting the Fenswood Scenario up and running is to actually get the UAV to do something. The previous steps simply started the simulator up, but now we have to instruct and control the UAV. For now we have provided an example controller to all students in the same FenswoodScenario repository under example_controller_python_ap . This section will take you through step by step as to how to download and run the example, a bit of information about what the example contains. This information is also available in the example repository readme.","title":"Running the Example UAV Controller"},{"location":"tutorials/running_controller/#running-the-example-controller","text":"First, open up a terminal and start up the Fenswood Scenario Simulator if you haven't already (Refer to ). Double check it is open by going to Gazebo Web at localhost:8080 Then, open up a second terminal and navigate to the FenswoodScenario repository folder. The example controller can be started by running the following: myuser@my-machine:~/Documents/FenswoodScenario$ docker-compose -f docker-compose.example_drone_controller.yaml up With this command, the controller will start off and attempt to find a drone on the network. If a drone has not been found, try restarting the both the Fenswood Scenario and the controller. Once a drone has been found, it will attempt to connect to the ardupilot. Once connected the path the vehicle will take is initialised and it is ready to fly if the user sends a mission go. Be patient, sometimes the ardupilot SITL can be quite slow to respond. Leave it for up to 2 or 3 minutes before trying again. Now to send a mission go, you can use the provided simple UI that is started with the FenswoodScenario. Navigate to localhost:3000 in the browser, and a UI will start up: If it says connected to rosbridge in green, then you are ready to send a mission start command. Press the Green GO Button. If you go to the terminal it should start sending waypoints. In the UI the camera image should start to change as the vehicle takes off, and you should see the vehicle takeoff in gazebo web as well. Then you should hopefully see its attempt to follow a preset trajectory towards the target location. This full process can be seen in the following gif (The commands are outdated, but you should see something very similar): The landing:","title":"Running the Example Controller"},{"location":"tutorials/running_controller/#what-is-the-example-controller","text":"So what exactly is the example controller doing? Lets first start with what it is communicating with. On a real drone, the thing that controls the lower level operations of the drone is the Autopilot or Flight controller . The autopilot contains software which allows for different flight modes and translates hight level commands to motor voltages to fly the drone. As you might have come across, the primary with of controlling the autopilot is through sending Mavlink messages. Now the autopilot software itself can be swapped out and changed. For this scenario, we use the Ardupilot Arducopter firmware for the flight controller. It is important to know the specific type of software as different flight controller firmware requires the use of different flight mode and instructions. The Fenswood Scenario simulator utilises the Ardupilot Software In The Loop (SITL) simulator. This program is identical to the firmware that would be running onboard the flight controller. Then, within the example controller repository, there are two example controllers - one for Ardupilot (suffixed with ap ), and one for the PX4 firmware (suffixed with px4 ). You can use the former to communicate with the Ardupilot SITL. The example controller talks in ROS2 to the SITL via the Mavros translation node mentioned earlier. It sends commands for things like 'takeoff', 'go there' and 'land' via topics which the Mavros node advertises. The Mavros node takes subscribes to these topics and re-publishes them to the Flight Controller using Mavlink in a way Ardupilot understands. More details will be given in the next tutorial about how this controller works under the hood, and how to develop your own.","title":"What is the Example Controller"},{"location":"tutorials/starling_docker/","text":"Starling and Docker \u00b6 So now we have installed this thing called Docker - but what is it, and why does it matter to you as a user of Starling. For now, we recommend you treat docker as a special program that runs programs which we have written for you to use. For the purposes of this session we will not yet go into the details - we'll leave that for a future session, but we can at least give you a flavour of what Docker has allowed us to do. What is the purpose of Starling \u00b6 The purpose of Starling, for the use of this course, is to allow you to quickly and easily install and run a UAV simulation within a simulated environment, so that you can test your developed controllers against a semi-realistic scenario. Therefore Starling is a set of pre-built programs/executables, some of which are pre-configured for the following: Running a Physics Simulation with Visualisation Running the Drone autopilot control software locally (a.k.a Software In The Loop or SITL) Running the interface between Mavlink and other protocols such as the Robot Operating System (ROS) And many others... These pre-built programs, which we refer to as containers , are all available in the StarlingUAS repository on github . Together these containers form a modular ecosystem of drone systems which can be composed together to develop software for real drones. Any controllers developed via the simulator can be directly ported to run on a real drone. What 'magic' is docker doing \u00b6 Perhaps it is easiest to explain what we (and you) would have to do if docker did not exist! Each of the elements described above uses its own programs. For example the physics simulator is a program called gazebo . On each of your machines you would have to manually install gazebo and configure it to work. Then you would have to do the same for SITL, Mavlink, ROS and so on, and then make sure all of them work together - configuration files, scripts etc etc. And still this is without considering how to write software which will run on a drone on a different computer altogther (we don't want the 'but sir, it worked on my machine' syndrome!). With docker, we have essentially packaged up the software with all of it's dependencies and configurations to provide only the specific service we want it to provide. We have already figured out how to install and configure, say, gazebo, and how to get it running with everything else, put those instructions together and released it to you as a container . Almost as importantly, because the installation and configuration is baked into the container, the system itself runs in a consistent and replicatable environment , hopefully allowing reproducable results each time. This can be different from running 'bare metal' on your local machine where you may have accidentally changed a configuration without knowing - leading to things going wrong. All of this means that it's less work for you as the user, as you don't need to go through the difficulties of set-up and installation of all the many individual components. And it's better for us as we can get down to the interesting stuff quicker making life better for everyone! We want to leave it like this for now, but if you want more detail you can see this tutorial here. I would recommend you come back after you have finished section this tutorial.","title":"2. Starling and Docker"},{"location":"tutorials/starling_docker/#starling-and-docker","text":"So now we have installed this thing called Docker - but what is it, and why does it matter to you as a user of Starling. For now, we recommend you treat docker as a special program that runs programs which we have written for you to use. For the purposes of this session we will not yet go into the details - we'll leave that for a future session, but we can at least give you a flavour of what Docker has allowed us to do.","title":"Starling and Docker"},{"location":"tutorials/starling_docker/#what-is-the-purpose-of-starling","text":"The purpose of Starling, for the use of this course, is to allow you to quickly and easily install and run a UAV simulation within a simulated environment, so that you can test your developed controllers against a semi-realistic scenario. Therefore Starling is a set of pre-built programs/executables, some of which are pre-configured for the following: Running a Physics Simulation with Visualisation Running the Drone autopilot control software locally (a.k.a Software In The Loop or SITL) Running the interface between Mavlink and other protocols such as the Robot Operating System (ROS) And many others... These pre-built programs, which we refer to as containers , are all available in the StarlingUAS repository on github . Together these containers form a modular ecosystem of drone systems which can be composed together to develop software for real drones. Any controllers developed via the simulator can be directly ported to run on a real drone.","title":"What is the purpose of Starling"},{"location":"tutorials/starling_docker/#what-magic-is-docker-doing","text":"Perhaps it is easiest to explain what we (and you) would have to do if docker did not exist! Each of the elements described above uses its own programs. For example the physics simulator is a program called gazebo . On each of your machines you would have to manually install gazebo and configure it to work. Then you would have to do the same for SITL, Mavlink, ROS and so on, and then make sure all of them work together - configuration files, scripts etc etc. And still this is without considering how to write software which will run on a drone on a different computer altogther (we don't want the 'but sir, it worked on my machine' syndrome!). With docker, we have essentially packaged up the software with all of it's dependencies and configurations to provide only the specific service we want it to provide. We have already figured out how to install and configure, say, gazebo, and how to get it running with everything else, put those instructions together and released it to you as a container . Almost as importantly, because the installation and configuration is baked into the container, the system itself runs in a consistent and replicatable environment , hopefully allowing reproducable results each time. This can be different from running 'bare metal' on your local machine where you may have accidentally changed a configuration without knowing - leading to things going wrong. All of this means that it's less work for you as the user, as you don't need to go through the difficulties of set-up and installation of all the many individual components. And it's better for us as we can get down to the interesting stuff quicker making life better for everyone! We want to leave it like this for now, but if you want more detail you can see this tutorial here. I would recommend you come back after you have finished section this tutorial.","title":"What 'magic' is docker doing"},{"location":"tutorials/summary/","text":"Summary and Conclusion \u00b6 Congratulations! You have gotten to the end of this tutorial! Especially if this is your first time touching linux and using this stuff, a lot of the content here can be daunting - but feel free to read it over again and hopefullly you will slowly come to understand what is going on. In this introductory tutorial, we have only really scratched the surface of a lot of the technologies that we've been using. If you wish to have a deeper understanding, I would recommend having a read through the official documentation of all of them. The docker and ROS2 tutorials are really good. But I wish to emphasise that you will hopefully not need an extremely deep understanding to use Starling. The next step after this tutorial is then to cover how you might actually build your own controller. This will go into more detail about Mavlink, ROS2 and Docker - including how to build your own projects and run them against the Fenswood Scenario Simulator!","title":"7. Summary and Conclusion"},{"location":"tutorials/summary/#summary-and-conclusion","text":"Congratulations! You have gotten to the end of this tutorial! Especially if this is your first time touching linux and using this stuff, a lot of the content here can be daunting - but feel free to read it over again and hopefullly you will slowly come to understand what is going on. In this introductory tutorial, we have only really scratched the surface of a lot of the technologies that we've been using. If you wish to have a deeper understanding, I would recommend having a read through the official documentation of all of them. The docker and ROS2 tutorials are really good. But I wish to emphasise that you will hopefully not need an extremely deep understanding to use Starling. The next step after this tutorial is then to cover how you might actually build your own controller. This will go into more detail about Mavlink, ROS2 and Docker - including how to build your own projects and run them against the Fenswood Scenario Simulator!","title":"Summary and Conclusion"}]}